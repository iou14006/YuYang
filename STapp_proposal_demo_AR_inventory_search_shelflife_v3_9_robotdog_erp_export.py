import os
import datetime as dt
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
from io import BytesIO

# PDF export (schedule suggestion)
try:
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.lib import colors
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import mm
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    _REPORTLAB_OK = True
except Exception:
    _REPORTLAB_OK = False


# ==========================================================
# YuYang / Skybit-PI â€” Stenter Customer Proposal Demo
# Two on-site pages -> Decision Layer (Profit/OTD/Carbon)
# + Physics (Steam/Exhaust T&RH/Airflow) + Event Timeline
# ==========================================================

st.set_page_config(page_title="YuYang Proposal Demo", layout="wide")

# -----------------------------
# PDF: Schedule Suggestion Export
# -----------------------------
def _find_cjk_font_paths() -> list:
    """Return candidate CJK font file paths for PDF export (cross-platform)."""
    cand = []
    # Windows common fonts
    cand += [
        r"C:\Windows\Fonts\msjh.ttc",  # Microsoft JhengHei
        r"C:\Windows\Fonts\msjhbd.ttc",
        r"C:\Windows\Fonts\msyh.ttc",  # Microsoft YaHei
        r"C:\Windows\Fonts\msyhbd.ttc",
        r"C:\Windows\Fonts\simhei.ttf",
        r"C:\Windows\Fonts\simsun.ttc",
    ]
    # Linux common fonts (container / servers)
    cand += [
        "/usr/share/fonts/truetype/arphic-gbsn00lp/gbsn00lp.ttf",
        "/usr/share/fonts/truetype/arphic-gkai00mp/gkai00mp.ttf",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        "/usr/share/fonts/truetype/noto/NotoSansCJKsc-Regular.otf",
    ]
    return [p for p in cand if os.path.exists(p)]

def _register_cjk_font() -> tuple[str, str]:
    """Register a CJK font for ReportLab and return (regular, bold) font names."""
    if not _REPORTLAB_OK:
        return ("Helvetica", "Helvetica-Bold")

    # If already registered, reuse
    if "CJK" in pdfmetrics.getRegisteredFontNames():
        return ("CJK", "CJK-Bold")

    font_paths = _find_cjk_font_paths()
    # Prefer TTF over TTC/OTF for maximum compatibility
    preferred = []
    for p in font_paths:
        ext = os.path.splitext(p)[1].lower()
        if ext == ".ttf":
            preferred.append(p)
    font_paths = preferred + [p for p in font_paths if p not in preferred]

    reg_name = "CJK"
    bold_name = "CJK-Bold"
    # Try register first workable font
    for p in font_paths:
        try:
            pdfmetrics.registerFont(TTFont(reg_name, p, subfontIndex=0))
            # Use same face as bold if no bold available
            pdfmetrics.registerFont(TTFont(bold_name, p, subfontIndex=0))
            return (reg_name, bold_name)
        except Exception:
            continue

    # fallback
    return ("Helvetica", "Helvetica-Bold")

def build_schedule_pdf_from_queue(
    queue_df: pd.DataFrame,
    now_ts: dt.datetime | None = None,
    rate_m_per_hr: float = 600.0,
    changeover_hr_same_line: float = 0.25,
) -> bytes:
    """Build a PDF (bytes) of schedule suggestion table from the priority queue."""
    if now_ts is None:
        now_ts = dt.datetime.now()

    if queue_df is None or len(queue_df) == 0:
        return b""

    # defensive copy and normalize types
    q = queue_df.copy()
    if "due" in q.columns:
        q["due"] = pd.to_datetime(q["due"], errors="coerce")

    # Ensure key columns exist
    for c in ["score","wo","flow_card","line","customer","otd","due","shelf_age_days","inventory_m",
              "shelf_loss_nt_per_m","profit_with_carbon_and_shelf_nt_per_m","total_quality_loss_nt","reasons"]:
        if c not in q.columns:
            q[c] = np.nan

    # Sort: score desc then due asc
    q = q.sort_values(["score","due"], ascending=[False, True], na_position="last").reset_index(drop=True)

    # Estimate start/finish per line (simple line-wise sequential model)
    line_state = {}
    for ln in q["line"].dropna().unique().tolist():
        line_state[ln] = {"t": now_ts, "has_job": False}

    est_start_list, est_finish_list, eta_status_list, reason_list, chg_cost_list = [], [], [], [], []

    for _, r in q.iterrows():
        ln = r.get("line", "UNKNOWN")
        if ln not in line_state:
            line_state[ln] = {"t": now_ts, "has_job": False}
        stt = line_state[ln]
        chg_hr = changeover_hr_same_line if stt["has_job"] else 0.0

        start = stt["t"] + dt.timedelta(hours=float(chg_hr))
        qty = r.get("inventory_m", np.nan)
        if pd.isna(qty) or float(qty) <= 0:
            qty = 1000.0  # demo fallback
        dur_hr = float(qty) / max(float(rate_m_per_hr), 1e-6)
        finish = start + dt.timedelta(hours=dur_hr)

        due = r.get("due", pd.NaT)
        eta_status = "å¯æº–äº¤"
        if pd.notna(due) and finish > due.to_pydatetime():
            eta_status = "å¯èƒ½å»¶èª¤"

        # changeover cost (demo): first job 0, subsequent jobs fixed
        chg_cost = 0 if not stt["has_job"] else 500

        # reasons
        reasons = r.get("reasons", "")
        if not isinstance(reasons, str) or reasons.strip() == "":
            parts = []
            try:
                age = float(r.get("shelf_age_days", np.nan))
                if age >= 30:
                    parts.append("åº«é½¡é«˜")
                elif age >= 20:
                    parts.append("åº«é½¡è¶…æ¨™")
            except Exception:
                pass
            if str(r.get("otd", "")) == "æœ‰é¢¨éšª":
                parts.append("äº¤æœŸé€¼è¿‘")
            try:
                prof = float(r.get("profit_with_carbon_and_shelf_nt_per_m", np.nan))
                if not np.isnan(prof) and prof < 0:
                    parts.append("å«ç¢³+åº«é½¡ç‚ºè² ")
            except Exception:
                pass
            reasons = " / ".join(parts) if parts else "å¸¸è¦"

        est_start_list.append(start)
        est_finish_list.append(finish)
        eta_status_list.append(eta_status)
        reason_list.append(reasons)
        chg_cost_list.append(chg_cost)

        stt["t"] = finish
        stt["has_job"] = True

    q["est_start"] = est_start_list
    q["est_finish"] = est_finish_list
    q["eta_status"] = eta_status_list
    q["sched_reason"] = reason_list
    q["changeover_cost_nt"] = chg_cost_list

    reg_font, bold_font = _register_cjk_font()

    buf = BytesIO()
    doc = SimpleDocTemplate(
        buf,
        pagesize=landscape(A4),
        leftMargin=12 * mm,
        rightMargin=12 * mm,
        topMargin=10 * mm,
        bottomMargin=10 * mm,
    )

    styles = getSampleStyleSheet()
    title = ParagraphStyle("title", parent=styles["Title"], fontName=bold_font, fontSize=18, leading=22, spaceAfter=8)
    h2 = ParagraphStyle("h2", parent=styles["Heading2"], fontName=bold_font, fontSize=12, leading=14, spaceBefore=6, spaceAfter=4)
    body = ParagraphStyle("body", parent=styles["BodyText"], fontName=reg_font, fontSize=9, leading=11)

    elems = []
    elems.append(Paragraph("å„ªå…ˆæ’ç”¢ - æ’ç¨‹å»ºè­°è¡¨ï¼ˆDemoè¼¸å‡ºï¼‰", title))
    elems.append(Paragraph(
        f"ç”Ÿæˆæ™‚é–“ï¼š{now_ts.strftime('%Y-%m-%d %H:%M')} ï½œå‡è¨­ç”¢èƒ½ï¼š{rate_m_per_hr:.0f} m/hr ï½œåŒç·šæ›ç·šæ™‚é–“ï¼š{changeover_hr_same_line:.2f} hr",
        body
    ))
    elems.append(Spacer(1, 6))
    elems.append(Paragraph("æ’åºè¦å‰‡èˆ‡è¼¸å‡ºæ¬„ä½èªªæ˜", h2))
    elems.append(Paragraph(
        "æ’åºä¾ Score ç”±é«˜åˆ°ä½ï¼ˆåº«é½¡è¶…æ¨™ã€å“è³ªæå¤±ã€äº¤æœŸé¢¨éšªã€å«ç¢³+åº«é½¡ç›ˆè™§ç‚ºè² ç­‰å› å­åŠ æ¬Šï¼‰ã€‚"
        "è¡¨å…§æä¾›æ¯ç­†å·¥å–®çš„æ’åºç†ç”±ã€é ä¼°æ›ç·šæˆæœ¬ã€é ä¼°é–‹å·¥/å®Œå·¥æ™‚é–“èˆ‡æº–äº¤åˆ¤æ–·ï¼Œä¾›ç”Ÿç®¡åšé€±æ’/æ—¥æ’åƒè€ƒã€‚",
        body
    ))
    elems.append(Spacer(1, 8))

    header = ["Rank","WO","æµç¨‹å¡","ç·šåˆ¥","å®¢æˆ¶","äº¤æœŸ","æº–äº¤(ç¾æ³)","é ä¼°é–‹å·¥","é ä¼°å®Œå·¥","ETAç‹€æ…‹",
              "åº«é½¡(å¤©)","å·é•·(m)","å“è³ªæå¤±(NT$/m)","å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)","æ›ç·šæˆæœ¬(NT$)","Score","æ’åºç†ç”±"]
    data = [header]

    for i, r in q.iterrows():
        def _fmt_dt(x):
            try:
                return x.strftime("%m-%d %H:%M")
            except Exception:
                return ""
        data.append([
            str(i + 1),
            str(r.get("wo","")),
            str(r.get("flow_card","")),
            str(r.get("line","")),
            str(r.get("customer","")),
            _fmt_dt(r.get("due", None)) if pd.notna(r.get("due", pd.NaT)) else "",
            str(r.get("otd","")),
            _fmt_dt(r.get("est_start", None)),
            _fmt_dt(r.get("est_finish", None)),
            str(r.get("eta_status","")),
            "" if pd.isna(r.get("shelf_age_days", np.nan)) else f"{int(float(r.get('shelf_age_days')))}",
            "" if pd.isna(r.get("inventory_m", np.nan)) else f"{float(r.get('inventory_m')):.0f}",
            "" if pd.isna(r.get("shelf_loss_nt_per_m", np.nan)) else f"{float(r.get('shelf_loss_nt_per_m')):.4f}",
            "" if pd.isna(r.get("profit_with_carbon_and_shelf_nt_per_m", np.nan)) else f"{float(r.get('profit_with_carbon_and_shelf_nt_per_m')):.4f}",
            "" if pd.isna(r.get("changeover_cost_nt", np.nan)) else f"{int(float(r.get('changeover_cost_nt'))):,}",
            "" if pd.isna(r.get("score", np.nan)) else f"{float(r.get('score')):.3f}",
            str(r.get("sched_reason","")),
        ])

    tbl = Table(data, repeatRows=1)
    ts = TableStyle([
        ("FONT", (0,0), (-1,0), bold_font, 9),
        ("BACKGROUND", (0,0), (-1,0), colors.HexColor("#E9EEF6")),
        ("TEXTCOLOR", (0,0), (-1,0), colors.HexColor("#102A43")),
        ("ALIGN", (0,0), (-1,0), "CENTER"),
        ("VALIGN", (0,0), (-1,-1), "MIDDLE"),
        ("GRID", (0,0), (-1,-1), 0.25, colors.HexColor("#CBD2D9")),
        ("FONT", (0,1), (-1,-1), reg_font, 8),
        ("ALIGN", (0,1), (0,-1), "CENTER"),
        ("ALIGN", (5,1), (9,-1), "CENTER"),
        ("ALIGN", (10,1), (11,-1), "RIGHT"),
        ("ALIGN", (12,1), (15,-1), "RIGHT"),
        ("ALIGN", (16,1), (16,-1), "LEFT"),
    ])

    # highlight risky rows
    for ridx in range(1, len(data)):
        eta = data[ridx][9]
        try:
            shelf = int(data[ridx][10]) if data[ridx][10] != "" else 0
        except Exception:
            shelf = 0
        try:
            prof = float(data[ridx][13]) if data[ridx][13] != "" else 0.0
        except Exception:
            prof = 0.0
        if eta == "å¯èƒ½å»¶èª¤":
            ts.add("BACKGROUND", (0, ridx), (-1, ridx), colors.HexColor("#FFF5F5"))
        if shelf >= 30:
            ts.add("TEXTCOLOR", (10, ridx), (10, ridx), colors.HexColor("#B91C1C"))
        if prof < 0:
            ts.add("TEXTCOLOR", (13, ridx), (13, ridx), colors.HexColor("#7C2D12"))

    tbl.setStyle(ts)
    elems.append(tbl)

    doc.build(elems)
    return buf.getvalue()


# -----------------------------
# ERP Export (Excel/PDF) for RobotDog Maintenance Tickets + PR/PO
# -----------------------------

def build_erp_excel(tickets_df: pd.DataFrame, pr_df: pd.DataFrame, po_df: pd.DataFrame) -> bytes:
    """Export ERP artifacts to an Excel workbook with multiple sheets."""
    out = BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl") as writer:
        (tickets_df if tickets_df is not None else pd.DataFrame()).to_excel(writer, index=False, sheet_name="MaintenanceTickets")
        (pr_df if pr_df is not None else pd.DataFrame()).to_excel(writer, index=False, sheet_name="PR")
        (po_df if po_df is not None else pd.DataFrame()).to_excel(writer, index=False, sheet_name="PO")

        # Simple pivot summary
        if tickets_df is not None and len(tickets_df) > 0:
            s = tickets_df.copy()
            if "created_ts" in s.columns:
                s["created_date"] = pd.to_datetime(s["created_ts"], errors="coerce").dt.date
            piv = s.pivot_table(index=["line"], values=["est_material_cost_nt"], aggfunc="sum", fill_value=0)
            piv.reset_index().to_excel(writer, index=False, sheet_name="Summary")
        else:
            pd.DataFrame([{ "note": "No tickets" }]).to_excel(writer, index=False, sheet_name="Summary")

    return out.getvalue()


def build_erp_pdf(tickets_df: pd.DataFrame, pr_df: pd.DataFrame, po_df: pd.DataFrame, title: str = "ERP åŒ¯å‡ºï¼ˆMaintenance / PR / POï¼‰") -> bytes:
    """Build a compact PDF report for ERP export (tickets + PR + PO)."""
    if not _REPORTLAB_OK:
        return b""

    reg_font, bold_font = _register_cjk_font()

    buf = BytesIO()
    doc = SimpleDocTemplate(
        buf,
        pagesize=A4,
        leftMargin=14 * mm,
        rightMargin=14 * mm,
        topMargin=12 * mm,
        bottomMargin=12 * mm,
    )

    styles = getSampleStyleSheet()
    ttl = ParagraphStyle("ttl", parent=styles["Title"], fontName=bold_font, fontSize=16, leading=20, spaceAfter=8)
    h2 = ParagraphStyle("h2", parent=styles["Heading2"], fontName=bold_font, fontSize=11, leading=14, spaceBefore=6, spaceAfter=4)
    body = ParagraphStyle("body", parent=styles["BodyText"], fontName=reg_font, fontSize=9, leading=11)

    elems = []
    elems.append(Paragraph(title, ttl))
    elems.append(Paragraph(f"ç”¢å‡ºæ™‚é–“ï¼š{dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", body))
    elems.append(Spacer(1, 6))

    def _table_from_df(df: pd.DataFrame, max_rows: int = 18):
        if df is None or len(df) == 0:
            return Table([["(empty)"]])
        view = df.copy().head(max_rows)
        # stringify datetimes for PDF
        for c in view.columns:
            if "ts" in c or "date" in c:
                view[c] = pd.to_datetime(view[c], errors="coerce").astype(str)
        data = [list(view.columns)] + view.astype(str).values.tolist()
        tbl = Table(data, repeatRows=1)
        tbl.setStyle(TableStyle([
            ("FONTNAME", (0,0), (-1,0), bold_font),
            ("FONTNAME", (0,1), (-1,-1), reg_font),
            ("FONTSIZE", (0,0), (-1,-1), 8),
            ("BACKGROUND", (0,0), (-1,0), colors.lightgrey),
            ("GRID", (0,0), (-1,-1), 0.25, colors.grey),
            ("VALIGN", (0,0), (-1,-1), "TOP"),
        ]))
        return tbl

    elems.append(Paragraph("Maintenance Tickets", h2))
    elems.append(_table_from_df(tickets_df, max_rows=16))
    elems.append(Spacer(1, 8))

    elems.append(Paragraph("PRï¼ˆè«‹è³¼ï¼‰", h2))
    elems.append(_table_from_df(pr_df, max_rows=18))
    elems.append(Spacer(1, 8))

    elems.append(Paragraph("POï¼ˆæ¡è³¼å–®ï¼‰", h2))
    elems.append(_table_from_df(po_df, max_rows=18))

    doc.build(elems)
    return buf.getvalue()

# -----------------------------
# Psychrometrics (engineering approximation)
# -----------------------------
def p_ws_tetens_pa(T_c: float) -> float:
    # Saturation vapor pressure (Pa), Tetens approximation
    return 610.94 * np.exp((17.625 * T_c) / (T_c + 243.04))

def humidity_ratio_w(T_c: float, RH_0to1: float, p_atm_pa: float = 101325.0) -> float:
    RH = float(np.clip(RH_0to1, 0.0, 1.0))
    p_ws = p_ws_tetens_pa(float(T_c))
    p_v = RH * p_ws
    return 0.62198 * (p_v / max(p_atm_pa - p_v, 1e-6))

def dryer_physics(
    speed_mmin: float,
    steam_kgph: float,
    airflow_m3ph: float,
    t_in_c: float,
    rh_in: float,
    t_out_c: float,
    rh_out: float,
    rho_air: float,
    p_atm: float,
    h_fg_kjkg: float,
    h_steam_kjkg: float,
    cp_air_kjkgk: float,
    eta_base: float,
) -> dict:
    """
    Physics-inspired (auditable) model:
    - moisture removal estimated from inlet/outlet humidity ratio & airflow
    - drying heat requirement = latent + sensible / efficiency
    - steam heat supply from steam mass flow and enthalpy drop
    """
    v_hr = max(speed_mmin * 60.0, 1e-6)  # m/hr
    steam_kgs = steam_kgph / 3600.0
    vdot_m3s = airflow_m3ph / 3600.0

    w_in = humidity_ratio_w(t_in_c, rh_in, p_atm)
    w_out = humidity_ratio_w(t_out_c, rh_out, p_atm)

    m_da_dot = rho_air * vdot_m3s               # kg_dry_air/s (approx)
    m_w_dot = m_da_dot * max(0.0, (w_out - w_in))  # kg_water/s

    # base latent + sensible (kW)
    q_evap_kw = m_w_dot * h_fg_kjkg
    q_air_kw = m_da_dot * cp_air_kjkgk * max(0.0, (t_out_c - t_in_c))

    # effective efficiency degrades when exhaust RH is high (driving force reduced)
    eta_eff = eta_base * (1.0 - 0.60 * max(0.0, (rh_out - 0.75)))  # demo degradation
    eta_eff = float(np.clip(eta_eff, 0.20, 0.95))

    q_req_kw = (q_evap_kw + q_air_kw) / max(eta_eff, 1e-6)
    q_steam_kw = steam_kgs * h_steam_kjkg

    kwh_th_per_m_req = q_req_kw / v_hr
    kwh_th_per_m_steam = q_steam_kw / v_hr

    steam_util = q_req_kw / max(q_steam_kw, 1e-6)  # >1 implies insufficient supply or losses

    return dict(
        w_in=w_in, w_out=w_out,
        m_w_dot_kgps=m_w_dot,
        q_evap_kw=q_evap_kw,
        q_air_kw=q_air_kw,
        eta_eff=eta_eff,
        q_req_kw=q_req_kw,
        q_steam_kw=q_steam_kw,
        kwh_th_per_m_req=kwh_th_per_m_req,
        kwh_th_per_m_steam=kwh_th_per_m_steam,
        steam_util=steam_util,
    )

# -----------------------------
# Demo data aligned to on-site pages
# -----------------------------
def generate_demo_orders(n: int = 14, seed: int = 25) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    now = dt.datetime.now()

    recipes = [f"25B{rng.integers(8000, 8999)}A" for _ in range(n)]
    wos = [f"{rng.integers(25000000, 25999999)}" for _ in range(n)]
    markets = rng.choice(["EU", "US", "JP", "TW"], size=n)
    customers = rng.choice(["Brand A", "Brand B", "Brand C", "Brand D"], size=n)
    lines = rng.choice(["LINE-A", "LINE-B", "LINE-C", "LINE-D"], size=n)
    flow_cards = [f"03{rng.integers(0,999999):06d}" for _ in range(n)]

    rows = []
    for i in range(n):
        speed = float(rng.uniform(20.0, 45.0))      # m/min
        zone_set = float(rng.uniform(170, 195))
        zone_temps = (zone_set + rng.normal(0, 2.5, size=8)).clip(155, 210)

        fan_hz = (35 + rng.normal(0, 1.2, size=8)).clip(25, 50)
        width_mm = (rng.normal(1655, 4.5, size=8)).clip(1540, 1700)

        ex_f_hz = float(np.clip(40 + rng.normal(0, 2.0), 25, 55))
        ex_b_hz = float(np.clip(40 + rng.normal(0, 2.0), 25, 55))
        cool_hz = float(np.clip(30 + rng.normal(0, 1.5), 15, 45))

        voltage = float(np.clip(380 + rng.normal(0, 6), 350, 410))
        current = float(np.clip(120 + rng.normal(0, 15), 60, 200))
        power_kw = float(max(15.0, (voltage * current * 0.85) / 1000.0))

        steam_kgph = float(rng.uniform(700, 1600))
        airflow_m3ph = float(rng.uniform(9000, 26000))
        t_in = float(rng.uniform(24, 34))
        rh_in = float(rng.uniform(0.45, 0.75))
        t_out = float(rng.uniform(58, 88))
        rh_out = float(rng.uniform(0.60, 0.95))

        plan_m = int(rng.integers(1800, 7000))
        done_m = int(rng.integers(300, plan_m - 100))
        due = now + dt.timedelta(hours=int(rng.integers(6, 72)))

        sell_price = float(rng.uniform(22.5, 29.0))

        row = dict(
            ts=now,
            line=str(lines[i]),
            flow_card=str(flow_cards[i]),
            start_ts=now - dt.timedelta(hours=float(rng.uniform(0.5, 10.0))),
            wo=wos[i],
            barcode=recipes[i],
            recipe=recipes[i],
            market=markets[i],
            customer=customers[i],
            speed_mmin=speed,
            plan_m=plan_m,
            done_m=done_m,
            due=due,
            exhaust_front_hz=ex_f_hz,
            exhaust_back_hz=ex_b_hz,
            cooling_hz=cool_hz,
            voltage_v=voltage,
            current_a=current,
            power_kw=power_kw,
            steam_kgph=steam_kgph,
            airflow_m3ph=airflow_m3ph,
            inlet_temp_c=t_in,
            inlet_rh=rh_in,
            exhaust_temp_c=t_out,
            exhaust_rh=rh_out,
            sell_price_nt_per_m=sell_price,
        )
        # zone fields (match the 1..8 layout)
        for z in range(1, 9):
            row[f"zone_temp_{z}"] = float(zone_temps[z-1])
            row[f"fan_hz_{z}"] = float(fan_hz[z-1])
            row[f"width_mm_{z}"] = float(width_mm[z-1])
        rows.append(row)

    return pd.DataFrame(rows)


# -----------------------------
# AR (Accounts Receivable) â€” proposal-friendly cash view
# -----------------------------
def generate_demo_ar(orders: pd.DataFrame, seed: int = 7) -> pd.DataFrame:
    """
    Create demo AR entries based on orders.
    In real deployment, replace with ERP AR / invoice tables.
    """
    rng = np.random.default_rng(seed)
    now = dt.datetime.now()

    # Payment terms by market (demo)
    term_days_map = {"EU": 60, "US": 45, "JP": 60, "TW": 30}

    rows = []
    for r in orders.itertuples(index=False):
        # Assume invoice at partial progress for demo; multiple invoices possible in real ERP
        invoiced_m = int(max(200, min(r.done_m, r.plan_m) * rng.uniform(0.70, 0.95)))
        invoice_amount = float(invoiced_m * r.sell_price_nt_per_m)

        # Partial received
        paid_ratio = float(np.clip(rng.normal(0.35, 0.25), 0.0, 0.95))
        paid_amount = invoice_amount * paid_ratio
        ar_amount = max(0.0, invoice_amount - paid_amount)

        term_days = int(term_days_map.get(r.market, 45))
        invoice_date = now - dt.timedelta(days=int(rng.integers(5, 50)))
        due_date = invoice_date + dt.timedelta(days=term_days)

        # Some overdue cases
        if rng.random() < 0.35:
            due_date = now - dt.timedelta(days=int(rng.integers(1, 35)))

        days_overdue = int((now - due_date).days)
        days_to_due = int((due_date - now).days)

        # Risk score: tie to profit + overdue + market
        market_risk = {"EU": 0.35, "US": 0.25, "JP": 0.20, "TW": 0.15}.get(r.market, 0.25)
        risk = 0.30 * market_risk + 0.45 * (1.0 if days_overdue > 0 else 0.0)
        risk = float(np.clip(risk + rng.normal(0, 0.05), 0.0, 1.0))

        if days_overdue > 30:
            bucket = "90+"
        elif days_overdue > 0:
            bucket = "1-30"
        elif days_to_due <= 7:
            bucket = "0-7"
        else:
            bucket = "current"

        rows.append(dict(
            wo=r.wo,
            barcode=r.barcode,
            customer=r.customer,
            market=r.market,
            invoice_no=f"INV-{str(r.wo)[-6:]}-{int(rng.integers(10,99))}",
            invoice_date=invoice_date,
            due_date=due_date,
            term_days=term_days,
            invoiced_m=invoiced_m,
            invoice_amount_nt=invoice_amount,
            paid_amount_nt=paid_amount,
            ar_amount_nt=ar_amount,
            days_overdue=days_overdue,
            bucket=bucket,
            risk_score=risk,
        ))

    ar = pd.DataFrame(rows)

    def risk_label(x: float) -> str:
        if x >= 0.70: return "ğŸ”´ é«˜é¢¨éšª"
        if x >= 0.45: return "ğŸŸ¡ æ³¨æ„"
        return "ğŸŸ¢ æ­£å¸¸"
    ar["risk"] = ar["risk_score"].apply(risk_label)

    return ar


# -----------------------------
# Inventory / Shelf-life â€” fabric aging cost (proposal-friendly)
# -----------------------------
def generate_demo_inventory(orders: pd.DataFrame, seed: int = 11) -> pd.DataFrame:
    """Create demo inventory rolls for shelf-life management.
    In real deployment, replace with WMS/ERP receiving records.
    """
    rng = np.random.default_rng(seed)
    now = dt.datetime.now()

    rows = []
    for r in orders.itertuples(index=False):
        # Assume each work order produces 1~3 rolls in inventory
        n_roll = int(rng.integers(1, 4))
        produced_m = int(max(0, r.done_m))
        if produced_m <= 0:
            continue
        splits = rng.dirichlet(np.ones(n_roll))
        for j in range(n_roll):
            qty_m = int(max(80, produced_m * splits[j]))
            inbound_days_ago = int(rng.integers(0, 38))  # some rolls are old
            inbound_date = now - dt.timedelta(days=inbound_days_ago)
            rows.append(dict(
                roll_id=f"ROLL-{r.wo}-{j+1}",
                wo=r.wo,
                flow_card=getattr(r, "flow_card", None),
                barcode=r.barcode,
                customer=r.customer,
                market=r.market,
                line=getattr(r, "line", None),
                inbound_date=inbound_date,
                qty_m=qty_m,
            ))
    inv = pd.DataFrame(rows)
    return inv

def apply_shelf_life(
    orders_enriched: pd.DataFrame,
    inventory_rolls: pd.DataFrame,
    shelf_threshold_days: int = 20,
    loss_nt_per_m_per_day: float = 0.12,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """Compute shelf-age risk & quality loss cost.
    - When shelf age > threshold, add a 'quality risk loss' cost (NT$/m).
    """
    now = dt.datetime.now()
    inv = inventory_rolls.copy()
    inv["shelf_age_days"] = (now - inv["inbound_date"]).dt.days.clip(lower=0)

    # roll-level loss
    over = (inv["shelf_age_days"] - int(shelf_threshold_days)).clip(lower=0)
    inv["quality_loss_nt"] = over * float(loss_nt_per_m_per_day) * inv["qty_m"]
    inv["quality_loss_nt_per_m"] = (inv["quality_loss_nt"] / inv["qty_m"].replace(0, np.nan)).fillna(0.0)

    def shelf_label(days: int) -> str:
        if days > shelf_threshold_days + 10:
            return "ğŸ”´ è¶…é½¡"
        if days > shelf_threshold_days:
            return "ğŸŸ¡ æ¥è¿‘é¢¨éšª"
        return "ğŸŸ¢ æ­£å¸¸"
    inv["shelf_risk"] = inv["shelf_age_days"].apply(shelf_label)

    # WO-level aggregation (use worst age / weighted loss per m)
    wo_agg = inv.groupby("wo", as_index=False).apply(
        lambda g: pd.Series({
            "shelf_age_days": int(g["shelf_age_days"].max()),
            "shelf_loss_nt_per_m": float((g["quality_loss_nt"].sum()) / max(g["qty_m"].sum(), 1e-6)),
            "shelf_risk": shelf_label(int(g["shelf_age_days"].max())),
            "inventory_m": int(g["qty_m"].sum()),
        })
    ).reset_index(drop=True)

    out = orders_enriched.merge(wo_agg, on="wo", how="left")
    out["shelf_age_days"] = out["shelf_age_days"].fillna(0).astype(int)
    out["shelf_loss_nt_per_m"] = out["shelf_loss_nt_per_m"].fillna(0.0)
    out["shelf_risk"] = out["shelf_risk"].fillna("ğŸŸ¢ æ­£å¸¸")
    out["inventory_m"] = out["inventory_m"].fillna(0).astype(int)

    out["profit_with_carbon_and_shelf_nt_per_m"] = out["profit_with_carbon_nt_per_m"] - out["shelf_loss_nt_per_m"]
    return out, inv

def attach_ar_profit(ar: pd.DataFrame, orders_enriched: pd.DataFrame) -> pd.DataFrame:
    """
    Map unit economics to AR rows so we can show 'AR backed profit' and 'carbon adjusted profit'.
    """
    m = orders_enriched.set_index("wo")
    out = ar.copy()

    out["sell_price_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "sell_price_nt_per_m"]) if x in m.index else 0.0)
    out["unit_cost_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "unit_cost_nt_per_m"]) if x in m.index else 0.0)
    out["internal_carbon_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "internal_carbon_nt_per_m"]) if x in m.index else 0.0)
    out["profit_with_carbon_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "profit_with_carbon_nt_per_m"]) if x in m.index else 0.0)
    out["shelf_loss_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "shelf_loss_nt_per_m"]) if x in m.index else 0.0)
    out["profit_with_carbon_and_shelf_nt_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "profit_with_carbon_and_shelf_nt_per_m"]) if x in m.index else 0.0)
    out["carbon_kgco2_per_m"] = out["wo"].map(lambda x: float(m.loc[x, "carbon_kgco2_per_m"]) if x in m.index else 0.0)

    # Margin ratio (auditable approximation)
    out["margin_ratio_carbon"] = (out["sell_price_nt_per_m"] - (out["unit_cost_nt_per_m"] + out["internal_carbon_nt_per_m"] + out["shelf_loss_nt_per_m"])) / out["sell_price_nt_per_m"].replace(0, np.nan)
    out["margin_ratio_carbon"] = out["margin_ratio_carbon"].replace([np.inf, -np.inf], 0.0).fillna(0.0).clip(-1.0, 1.0)

    out["ar_profit_with_carbon_nt"] = out["ar_amount_nt"] * out["margin_ratio_carbon"]
    return out

# -----------------------------
# Decision layer (profit/OTD/carbon)
# -----------------------------
def enrich_decision_layer(
    df: pd.DataFrame,
    # cost
    elec_price_nt_per_kwh: float,
    labor_nt_per_hr: float,
    machine_nt_per_hr: float,
    overhead_nt_per_m: float,
    steam_price_proxy_nt_per_kwhth: float,
    # physics
    p_atm: float,
    rho_air: float,
    eta_base: float,
    h_fg_kjkg: float,
    h_steam_kjkg: float,
    cp_air_kjkgk: float,
    # emissions
    ef_elec: float,
    ef_steam: float,
    internal_carbon_nt_per_t: float,
) -> pd.DataFrame:
    out = df.copy()
    phys = []

    for r in out.itertuples(index=False):
        ph = dryer_physics(
            speed_mmin=r.speed_mmin,
            steam_kgph=r.steam_kgph,
            airflow_m3ph=r.airflow_m3ph,
            t_in_c=r.inlet_temp_c,
            rh_in=r.inlet_rh,
            t_out_c=r.exhaust_temp_c,
            rh_out=r.exhaust_rh,
            rho_air=rho_air,
            p_atm=p_atm,
            h_fg_kjkg=h_fg_kjkg,
            h_steam_kjkg=h_steam_kjkg,
            cp_air_kjkgk=cp_air_kjkgk,
            eta_base=eta_base,
        )
        phys.append(ph)

    out["eta_eff"] = [p["eta_eff"] for p in phys]
    out["kwh_th_per_m_req"] = [p["kwh_th_per_m_req"] for p in phys]
    out["kwh_th_per_m_steam"] = [p["kwh_th_per_m_steam"] for p in phys]
    out["steam_util"] = [p["steam_util"] for p in phys]

    m_per_hr = out["speed_mmin"] * 60.0
    out["kwh_elec_per_m_est"] = (out["power_kw"] / m_per_hr.replace(0, np.nan)).fillna(0.0)

    energy_nt_per_m = out["kwh_elec_per_m_est"] * elec_price_nt_per_kwh + out["kwh_th_per_m_req"] * steam_price_proxy_nt_per_kwhth
    labor_nt_per_m = (labor_nt_per_hr / m_per_hr.replace(0, np.nan)).fillna(0.0)
    machine_nt_per_m = (machine_nt_per_hr / m_per_hr.replace(0, np.nan)).fillna(0.0)

    out["unit_cost_nt_per_m"] = energy_nt_per_m + labor_nt_per_m + machine_nt_per_m + overhead_nt_per_m
    out["profit_nt_per_m"] = out["sell_price_nt_per_m"] - out["unit_cost_nt_per_m"]

    out["carbon_kgco2_per_m"] = out["kwh_elec_per_m_est"] * ef_elec + out["kwh_th_per_m_req"] * ef_steam
    out["internal_carbon_nt_per_m"] = (out["carbon_kgco2_per_m"] / 1000.0) * internal_carbon_nt_per_t
    out["profit_with_carbon_nt_per_m"] = out["sell_price_nt_per_m"] - (out["unit_cost_nt_per_m"] + out["internal_carbon_nt_per_m"])

    out["remain_m"] = (out["plan_m"] - out["done_m"]).clip(lower=0)
    out["eta_hr"] = (out["remain_m"] / m_per_hr.replace(0, np.nan)).fillna(np.inf)
    now = dt.datetime.now()
    finish = now + pd.to_timedelta(out["eta_hr"], unit="h")
    slack_hr = (out["due"] - finish).dt.total_seconds() / 3600.0

    def otd_label(x: float) -> str:
        if x >= 2:
            return "ğŸŸ¢ æº–äº¤"
        if x >= -2:
            return "ğŸŸ¡ é¢¨éšª"
        return "ğŸ”´ é€¾æœŸ"
    out["otd"] = slack_hr.apply(otd_label)

    return out

# -----------------------------
# Event engine (ties order page & asset page)
# -----------------------------
def detect_events(row: pd.Series) -> list[dict]:
    now = dt.datetime.now()
    events: list[dict] = []

    # exhaust RH
    if row["exhaust_rh"] > 0.88:
        events.append(dict(ts=now, severity="ğŸ”´", event="EXH_RH_HIGH", subsystem="Exhaust/Dehumid",
                           explain=f"æ’é¢¨RH={row['exhaust_rh']*100:.1f}% åé«˜ â†’ è’¸ç™¼é©…å‹•åŠ›ä¸‹é™ã€èƒ½è€—ä¸Šå‡",
                           impact_nt_per_m=-0.9))
    elif row["exhaust_rh"] > 0.80:
        events.append(dict(ts=now, severity="ğŸŸ¡", event="EXH_RH_ELEVATED", subsystem="Exhaust/Dehumid",
                           explain=f"æ’é¢¨RH={row['exhaust_rh']*100:.1f}% åé«˜ â†’ èƒ½è€—/å“è³ªé¢¨éšªä¸Šå‡",
                           impact_nt_per_m=-0.4))

    # airflow
    if row["airflow_m3ph"] < 11000:
        events.append(dict(ts=now, severity="ğŸ”´", event="AIRFLOW_DROP", subsystem="Fan/Airflow",
                           explain=f"é¢¨é‡={row['airflow_m3ph']:.0f} mÂ³/h åä½ â†’ æ’æ¿•èƒ½åŠ›ä¸è¶³",
                           impact_nt_per_m=-0.7))
    elif row["airflow_m3ph"] < 12500:
        events.append(dict(ts=now, severity="ğŸŸ¡", event="AIRFLOW_LOW", subsystem="Fan/Airflow",
                           explain=f"é¢¨é‡={row['airflow_m3ph']:.0f} mÂ³/h åä½ â†’ å»ºè­°æª¢æŸ¥VFD/æ¿¾ç¶²/çš®å¸¶",
                           impact_nt_per_m=-0.3))

    # steam util
    if row["steam_util"] > 1.20:
        events.append(dict(ts=now, severity="ğŸ”´", event="STEAM_UTIL_HIGH", subsystem="Steam/Heater",
                           explain=f"ç†±éœ€æ±‚/è’¸æ°£ä¾›ç†±æ¯”={row['steam_util']:.2f} â†’ å¯èƒ½æ¼é¢¨/æ•£ç†±/è’¸æ°£ä¸è¶³",
                           impact_nt_per_m=-0.8))
    elif row["steam_util"] > 1.05:
        events.append(dict(ts=now, severity="ğŸŸ¡", event="STEAM_EFF_LOW", subsystem="Steam/Heater",
                           explain=f"ç†±éœ€æ±‚/è’¸æ°£ä¾›ç†±æ¯”={row['steam_util']:.2f} â†’ æ•ˆç‡åä½ï¼Œå»ºè­°æŸ¥æ’é¢¨/ç–æ°´/ä¿æº«",
                           impact_nt_per_m=-0.35))

    # width stability (chain/tension)
    widths = [row[f"width_mm_{i}"] for i in range(1, 9)]
    width_std = float(np.std(widths))
    if width_std > 6.0:
        events.append(dict(ts=now, severity="ğŸ”´", event="WIDTH_UNSTABLE", subsystem="Chain/Tension",
                           explain=f"å®šå‹å¯¬åº¦æ³¢å‹•STD={width_std:.1f}mm â†’ å¼µåŠ›/éˆæ¢/å¤¾å…·å¯èƒ½ç•°å¸¸",
                           impact_nt_per_m=-0.6))
    elif width_std > 4.0:
        events.append(dict(ts=now, severity="ğŸŸ¡", event="WIDTH_VARIANCE", subsystem="Chain/Tension",
                           explain=f"å®šå‹å¯¬åº¦æ³¢å‹•STD={width_std:.1f}mm â†’ å»ºè­°æª¢æŸ¥å¼µåŠ›/å¤¾å…·ç£¨è€—",
                           impact_nt_per_m=-0.25))

    # power
    if row["voltage_v"] < 360 or row["voltage_v"] > 400:
        events.append(dict(ts=now, severity="ğŸ”´", event="VOLTAGE_ANOMALY", subsystem="Power/VFD",
                           explain=f"é›»å£“={row['voltage_v']:.0f}V ç•°å¸¸ â†’ å¯èƒ½å½±éŸ¿é¢¨è»Š/è®Šé »ç©©å®š",
                           impact_nt_per_m=-0.5))

    return events

# -----------------------------
# Robot Dog Inspection (PoC via CSV/JSON; here demo generator)
# -----------------------------
def generate_demo_robotdog_runs(lines=("LINE-A","LINE-B","LINE-C","LINE-D"), seed: int = 123, n: int = 60) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    now = dt.datetime.now()
    subsystems = ["Fan & Airflow","Steam / Heater","Exhaust / Dehumid","Chain / Tension","Cooling","Power / VFD","Safety"]
    anomaly_types = [
        "HOTSPOT_PANEL", "STEAM_LEAK", "BEARING_NOISE", "BELT_SLIP",
        "DUCT_BLOCKAGE", "OIL_LEAK", "OBSTACLE", "ABNORMAL_VIB"
    ]
    rows = []
    for i in range(n):
        line = rng.choice(lines)
        subsystem = rng.choice(subsystems)
        atype = rng.choice(anomaly_types)
        severity = rng.choice(["ğŸŸ¢","ğŸŸ¡","ğŸ”´"], p=[0.65, 0.25, 0.10])

        ir_max_c = float(rng.uniform(45, 110))     # thermal max
        noise_db = float(rng.uniform(45, 95))      # acoustic
        vib_rms  = float(rng.uniform(0.2, 4.0))    # vibration
        gas_ppm  = float(rng.uniform(0, 200))      # gas proxy
        conf     = float(np.clip(rng.normal(0.78, 0.12), 0.2, 0.99))

        rows.append(dict(
            ts=now - dt.timedelta(minutes=int(rng.integers(1, 720))),
            line=str(line),
            subsystem=subsystem,
            anomaly_type=atype,
            severity=severity,
            ir_max_c=ir_max_c,
            noise_db=noise_db,
            vib_rms=vib_rms,
            gas_ppm=gas_ppm,
            confidence=conf,
            evidence_uri=f"robotdog://run/{i}",
        ))
    return pd.DataFrame(rows).sort_values("ts")

def robotdog_to_events(obs: pd.DataFrame) -> pd.DataFrame:
    """
    Convert robot dog observations into the same 'event timeline' schema.
    Columns: ts, severity, event, subsystem, explain, impact_nt_per_m, line, evidence_uri
    """
    if obs is None or len(obs) == 0:
        return pd.DataFrame(columns=["ts","severity","event","subsystem","explain","impact_nt_per_m","line","evidence_uri"])

    def impact_rule(r) -> float:
        base = {"ğŸŸ¢": -0.05, "ğŸŸ¡": -0.25, "ğŸ”´": -0.80}.get(r["severity"], -0.1)
        bump = 0.0
        if r["anomaly_type"] in ("STEAM_LEAK","DUCT_BLOCKAGE"): bump -= 0.25
        if r["anomaly_type"] in ("BEARING_NOISE","ABNORMAL_VIB","BELT_SLIP"): bump -= 0.20
        if r["anomaly_type"] in ("HOTSPOT_PANEL","OIL_LEAK"): bump -= 0.15
        if r["anomaly_type"] == "OBSTACLE": bump -= 0.10
        return float((base + bump) * float(r["confidence"]))

    def explain_rule(r) -> str:
        return (
            f"æ©Ÿå™¨ç‹—å·¡æª¢ï¼š{r['anomaly_type']}ï½œIRmax={r['ir_max_c']:.1f}Â°Cï½œ"
            f"Noise={r['noise_db']:.1f}dBï½œVib={r['vib_rms']:.2f}ï½œGas={r['gas_ppm']:.0f}ppmï½œ"
            f"conf={r['confidence']:.2f}"
        )

    out = obs.copy()
    out["event"] = out["anomaly_type"].astype(str)
    out["explain"] = out.apply(explain_rule, axis=1)
    out["impact_nt_per_m"] = out.apply(impact_rule, axis=1)
    if "line" not in out.columns:
        out["line"] = "UNKNOWN"

    return out[["ts","severity","event","subsystem","explain","impact_nt_per_m","line","evidence_uri"]]


def build_asset_cards(row: pd.Series) -> pd.DataFrame:
    fan_hz_mean = float(np.mean([row[f"fan_hz_{i}"] for i in range(1, 9)]))
    width_std = float(np.std([row[f"width_mm_{i}"] for i in range(1, 9)]))

    cards = [
        dict(subsystem="Fan & Airflow", kpi1="airflow_m3ph", v1=float(row["airflow_m3ph"]), kpi2="fan_hz_mean", v2=fan_hz_mean),
        dict(subsystem="Steam / Heater", kpi1="steam_kgph", v1=float(row["steam_kgph"]), kpi2="steam_util", v2=float(row["steam_util"])),
        dict(subsystem="Exhaust / Dehumid", kpi1="exhaust_rh", v1=float(row["exhaust_rh"]), kpi2="exhaust_front_hz", v2=float(row["exhaust_front_hz"])),
        dict(subsystem="Chain / Tension", kpi1="width_std_mm", v1=width_std, kpi2="speed_mmin", v2=float(row["speed_mmin"])),
        dict(subsystem="Cooling", kpi1="cooling_hz", v1=float(row["cooling_hz"]), kpi2="exhaust_temp_c", v2=float(row["exhaust_temp_c"])),
        dict(subsystem="Power / VFD", kpi1="voltage_v", v1=float(row["voltage_v"]), kpi2="current_a", v2=float(row["current_a"])),
    ]
    df = pd.DataFrame(cards)

    def health(sub: str, v1: float, v2: float) -> str:
        if sub == "Exhaust / Dehumid":
            return "ğŸ”´" if v1 > 0.88 else ("ğŸŸ¡" if v1 > 0.80 else "ğŸŸ¢")
        if sub == "Fan & Airflow":
            return "ğŸ”´" if v1 < 10500 else ("ğŸŸ¡" if v1 < 12500 else "ğŸŸ¢")
        if sub == "Steam / Heater":
            return "ğŸ”´" if v2 > 1.20 else ("ğŸŸ¡" if v2 > 1.05 else "ğŸŸ¢")
        if sub == "Chain / Tension":
            return "ğŸ”´" if v1 > 6.0 else ("ğŸŸ¡" if v1 > 4.0 else "ğŸŸ¢")
        if sub == "Power / VFD":
            return "ğŸ”´" if (v1 < 360 or v1 > 400) else ("ğŸŸ¡" if (v1 < 370 or v1 > 395) else "ğŸŸ¢")
        return "ğŸŸ¢"
    df["health"] = [health(r.subsystem, r.v1, r.v2) for r in df.itertuples(index=False)]
    return df

# -----------------------------
# UI: Sidebar (proposal-friendly)
# -----------------------------
st.sidebar.title("ğŸ›ï¸ Proposal Demo Controls")

mode = st.sidebar.radio("å‘ˆç¾æ¨¡å¼", ["ğŸ’¼ ç¶“ç‡Ÿ / ESG / é‡‘èæ¨¡å¼ï¼ˆå»ºè­°å®¢æˆ¶ï¼‰", "ğŸ‘· å·¥ç¨‹å¸«æ¨¡å¼ï¼ˆç¾å ´/ç¨½æ ¸ï¼‰"], index=0)
show_formulas = st.sidebar.checkbox("ğŸ“ é¡¯ç¤ºç‰©ç†æ¨¡å‹å…¬å¼", value=(mode.startswith("ğŸ‘·")))
show_on_site_refs = st.sidebar.checkbox("ğŸ–¼ï¸ é¡¯ç¤ºç¾å ´å…©é åƒè€ƒåœ–", value=True)

st.sidebar.markdown("---")
st.sidebar.markdown("#### æˆæœ¬èˆ‡ç¢³åƒæ•¸ï¼ˆå¯å¿«é€Ÿåšæƒ…å¢ƒï¼‰")
elec_price = st.sidebar.number_input("é›»åƒ¹ NT$/kWh", 1.0, 12.0, 3.2, 0.1)
steam_price_proxy = st.sidebar.number_input("è’¸æ°£å–®åƒ¹ Proxy NT$/kWh_th", 0.5, 10.0, 2.2, 0.1)
labor_hr = st.sidebar.number_input("äººå·¥ NT$/hr", 200.0, 1600.0, 520.0, 10.0)
machine_hr = st.sidebar.number_input("æ©Ÿå° NT$/hr", 200.0, 3000.0, 900.0, 20.0)
overhead_m = st.sidebar.number_input("è£½é€ è²»ç”¨ NT$/m", 0.0, 5.0, 0.65, 0.05)

ef_elec = st.sidebar.number_input("é›»åŠ› EF kgCO2/kWh", 0.05, 1.5, 0.52, 0.01)
ef_steam = st.sidebar.number_input("è’¸æ°£ EF kgCO2/kWh_th", 0.05, 1.5, 0.25, 0.01)
internal_carbon = st.sidebar.number_input("å…§éƒ¨ç¢³åƒ¹ NT$/tCO2e", 0.0, 8000.0, 1200.0, 50.0)

st.sidebar.markdown("---")
st.sidebar.markdown("#### å¸ƒæ–™æ™‚æ•ˆåº«å­˜ï¼ˆShelf-lifeï¼‰")
shelf_threshold_days = st.sidebar.number_input("åº«é½¡é–€æª»(å¤©)", 5, 90, 20, 1)
loss_nt_per_m_per_day = st.sidebar.number_input("åº«é½¡æå¤±ä¿‚æ•¸ NT$/m/å¤©ï¼ˆè¶…éé–€æª»å¾Œï¼‰", 0.0, 5.0, 0.12, 0.01)

st.sidebar.markdown("---")
st.sidebar.markdown("#### ç‰©ç†åƒæ•¸ï¼ˆç¾å ´å¯æ ¡æº–ï¼‰")
p_atm = st.sidebar.number_input("å¤§æ°£å£“ Pa", value=101325.0, step=100.0)
rho_air = st.sidebar.number_input("ç©ºæ°£å¯†åº¦ kg/mÂ³", value=1.20, step=0.01)
eta_base = st.sidebar.slider("ä¹¾ç‡¥æ•ˆç‡ Î·", 0.30, 0.95, 0.75, 0.01)
h_fg = st.sidebar.number_input("æ°´è’¸ç™¼æ½›ç†± h_fg kJ/kg", value=2257.0, step=10.0)
h_steam = st.sidebar.number_input("è’¸æ°£æœ‰æ•ˆç„“å·® h_steam kJ/kg", value=2000.0, step=50.0)
cp_air = st.sidebar.number_input("ç©ºæ°£æ¯”ç†± cp kJ/kg/K", value=1.005, step=0.001)

# -----------------------------
# Data
# -----------------------------
if "orders_raw" not in st.session_state:
    st.session_state.orders_raw = generate_demo_orders()

orders = enrich_decision_layer(
    st.session_state.orders_raw,
    elec_price_nt_per_kwh=elec_price,
    labor_nt_per_hr=labor_hr,
    machine_nt_per_hr=machine_hr,
    overhead_nt_per_m=overhead_m,
    steam_price_proxy_nt_per_kwhth=steam_price_proxy,
    p_atm=p_atm,
    rho_air=rho_air,
    eta_base=eta_base,
    h_fg_kjkg=h_fg,
    h_steam_kjkg=h_steam,
    cp_air_kjkgk=cp_air,
    ef_elec=ef_elec,
    ef_steam=ef_steam,
    internal_carbon_nt_per_t=internal_carbon,
)


# -----------------------------
# Demo Inventory (Shelf-life)
# -----------------------------
if "inventory_demo" not in st.session_state:
    # Inventory is created from the enriched orders (so we have customer/market mapping)
    st.session_state.inventory_demo = generate_demo_inventory(orders)

orders, inventory = apply_shelf_life(
    orders_enriched=orders,
    inventory_rolls=st.session_state.inventory_demo,
    shelf_threshold_days=int(shelf_threshold_days),
    loss_nt_per_m_per_day=float(loss_nt_per_m_per_day),
)

# -----------------------------
# Demo AR (Accounts Receivable)
# -----------------------------
if "ar_demo" not in st.session_state:
    st.session_state.ar_demo = generate_demo_ar(orders)

ar = attach_ar_profit(st.session_state.ar_demo, orders)
# -----------------------------
# Priority queue (production scheduling) â€” session state
# -----------------------------
if "priority_queue" not in st.session_state:
    st.session_state.priority_queue = pd.DataFrame(columns=[
        "rank", "score", "wo", "flow_card", "line", "customer",
        "otd", "due", "shelf_age_days", "shelf_loss_nt_per_m",
        "total_quality_loss_nt", "profit_with_carbon_and_shelf_nt_per_m",
        "inventory_m", "created_at", "reasons"
    ])

# -----------------------------
# Header
# -----------------------------
st.title("ğŸ­ YuYang â€” Demoï¼ˆå…©é ç›£æ¸¬ â†’ ç«‹åˆ»è®ŠæˆéŒ¢èˆ‡ç¢³ï¼‰")

tabs = st.tabs([
"â‘  å¤šå·¥å–®ç›¤ï¼ˆExecutive Portfolioï¼‰",
    "â‘¡ å·¥å–®é ï¼ˆå°é½Šç¾å ´ç¬¬ 1 é ï¼‰",
    "â‘¢ è¨­å‚™é ï¼ˆå°é½Šç¾å ´ç¬¬ 2 é ï¼‰",
    "â‘£ äº‹ä»¶æ™‚é–“ç·šï¼ˆåŸå› ï¼éŒ¢ï¼‰",
    "â‘¤ AR çœ¼é¡ï¼ˆç¾å ´å³æ™‚ç–ŠåŠ ï¼‰",
    "â‘¥ ARï¼ˆæ‡‰æ”¶å¸³æ¬¾ï¼‰+ å³æ™‚æˆæœ¬ç›ˆè™§",
    "â‘¦ ç°¡å ±/æ“ä½œ-å°åœ‹éš›å¤§å» ",
    "â‘§ æ©Ÿå™¨ç‹—å·¡æª¢ï¼ˆRobot Dogï¼‰",

])

# -----------------------------
# Helpers: formula panel
# -----------------------------
def render_formulas():
    st.markdown("### ğŸ“ ä¹¾ç‡¥æ®µç‰©ç†æ¨¡å‹ï¼ˆå¯ç¨½æ ¸ï¼‰")
    st.markdown("**(A) å«æ¿•æ¯”ï¼ˆç”± Tã€RH æ¨ç®—ï¼‰**")
    st.latex(r"p_v = RH\cdot p_{ws}(T)")
    st.latex(r"w = 0.62198\cdot \frac{p_v}{p_{atm}-p_v}")
    st.markdown("**(B) è’¸ç™¼æ°´é‡ï¼ˆç”±é¢¨é‡èˆ‡å«æ¿•æ¯”å·®ï¼‰**")
    st.latex(r"\dot m_{da}\approx \rho_{air}\cdot \dot V")
    st.latex(r"\dot m_w = \dot m_{da}\cdot (w_{out}-w_{in})")
    st.markdown("**(C) ç†±éœ€æ±‚ï¼ˆè’¸ç™¼æ½›ç†± + ç©ºæ°£é¡¯ç†±ï¼‰**")
    st.latex(r"\dot Q_{req}=\frac{\dot m_w h_{fg}+\dot m_{da}c_p(T_{out}-T_{in})}{\eta}")
    st.markdown("**(D) è’¸æ°£ä¾›ç†±ï¼ˆç”±è’¸æ°£æµé‡ï¼‰**")
    st.latex(r"\dot Q_{steam}=\dot m_s\cdot h_{steam}")
    st.markdown("**(E) kWh/m â†’ kgCOâ‚‚/m â†’ NT$/m**")
    st.latex(r"v_{hr}=60v,\;\;E_{th}(kWh/m)=\frac{\dot Q_{req}(kW)}{v_{hr}(m/hr)}")
    st.latex(r"I(kgCO_2/m)=E_{elec}EF_{elec}+E_{th}EF_{steam}")
    st.latex(r"C_{carbon}(NT\$/m)=\frac{I}{1000}\cdot P_{carbon}")

# -----------------------------
# Tab 1: Portfolio
# -----------------------------
with tabs[0]:
    st.subheader("â‘  å¤šå·¥å–®ç›¤ï¼ˆå…ˆçœ‹éŒ¢ï¼Œå†çœ‹åŸå› ï¼‰")

    # --------------------------------------------------
    # 1) æ»¿ç·šå£“åŠ›ä¸‹ï¼šè·¨ç·šåˆ¥å·¥å–®å³æ™‚å°‹æ‰¾ï¼ˆæœå°‹å¼•æ“ï¼‰
    # --------------------------------------------------
    with st.container(border=True):
        st.markdown("### ğŸ” è·¨ç·šåˆ¥å·¥å–®å³æ™‚å°‹æ‰¾ï¼ˆæ»¿ç·šå£“åŠ›ä¸‹çš„å®šä½ï¼‰")
        key = st.text_input("è¼¸å…¥æµç¨‹å¡è™Ÿ / Barcode / å·¥å–®ï¼ˆä¾‹ï¼š03017270ï¼‰", value="", placeholder="03017270")
        if key:
            k = key.strip().lower()
            hit = orders[
                orders["flow_card"].astype(str).str.lower().str.contains(k)
                | orders["barcode"].astype(str).str.lower().str.contains(k)
                | orders["wo"].astype(str).str.lower().str.contains(k)
            ]
            if len(hit) == 0:
                st.warning("æ‰¾ä¸åˆ°è©²å·¥å–®/æµç¨‹å¡ï¼ˆDemo è³‡æ–™ï¼‰ã€‚")
            else:
                r = hit.iloc[0]
                c1, c2, c3, c4, c5 = st.columns([1.2, 1.0, 1.1, 1.3, 1.6])
                c1.metric("æµç¨‹å¡è™Ÿ", str(r["flow_card"]))
                c2.metric("ç·šåˆ¥", str(r["line"]))
                c3.metric("å·¥å–®", str(r["wo"]))
                c4.metric("æº–äº¤", str(r["otd"]), f"ETA {float(r['eta_hr']):.1f} hr")
                pct = float(r["done_m"] / max(r["plan_m"], 1)) if float(r["plan_m"]) > 0 else 0.0
                c5.metric("ç¢¼è¡¨é€²åº¦", f"{pct*100:.1f}%", f"{int(r['done_m']):,}/{int(r['plan_m']):,} m")
                st.progress(min(max(pct, 0.0), 1.0))
                # Quick status line
                late_flag = "âš  äº¤æœŸé¢¨éšª" if str(r["otd"]) != "ğŸŸ¢ æº–äº¤" else "âœ… æº–äº¤"
                shelf_flag = f"{str(r['shelf_risk'])} åº«é½¡ {int(r['shelf_age_days'])} å¤© / æå¤± {float(r['shelf_loss_nt_per_m']):.2f} NT$/m"
                st.caption(f"{late_flag} ï½œ {shelf_flag}")

    f1, f2, f3, f4 = st.columns([1.1, 1.1, 1.2, 1.8])
    with f1:
        otd_filter = st.selectbox("æº–äº¤", ["ALL", "ğŸŸ¢ æº–äº¤", "ğŸŸ¡ é¢¨éšª", "ğŸ”´ é€¾æœŸ"])
    with f2:
        market_filter = st.selectbox("å¸‚å ´", ["ALL"] + sorted(orders["market"].unique().tolist()))
    with f3:
        sort_by = st.selectbox("æ’åº", ["profit_with_carbon_nt_per_m", "profit_nt_per_m", "carbon_kgco2_per_m", "eta_hr"])
    with f4:
        q = st.text_input("æœå°‹ï¼ˆå·¥å–®/Barcode/å®¢æˆ¶ï¼‰")

    view = orders.copy()
    if otd_filter != "ALL":
        view = view[view["otd"] == otd_filter]
    if market_filter != "ALL":
        view = view[view["market"] == market_filter]
    if q:
        ql = q.lower()
        view = view[
            view["wo"].astype(str).str.lower().str.contains(ql)
            | view["barcode"].astype(str).str.lower().str.contains(ql)
            | view["customer"].astype(str).str.lower().str.contains(ql)
        ]

    view = view.sort_values(sort_by, ascending=(sort_by in ["carbon_kgco2_per_m", "eta_hr"]))

    show_cols = [
        "line", "flow_card",
        "otd", "wo", "barcode", "customer", "market",
        "speed_mmin", "eta_hr",
        "unit_cost_nt_per_m", "profit_nt_per_m", "internal_carbon_nt_per_m",
        "shelf_loss_nt_per_m", "profit_with_carbon_and_shelf_nt_per_m",
        "carbon_kgco2_per_m",
        "shelf_risk", "shelf_age_days", "inventory_m",
        "exhaust_rh", "airflow_m3ph", "steam_kgph", "steam_util"
    ]
    table = view[show_cols].copy()
    table["exhaust_rh"] = (table["exhaust_rh"] * 100.0).round(1).astype(str) + "%"

    table = table.rename(columns={
        "line": "ç·šåˆ¥", "flow_card": "æµç¨‹å¡è™Ÿ",
        "otd": "æº–äº¤", "wo": "å·¥å–®", "barcode": "Barcode", "customer": "å®¢æˆ¶", "market": "å¸‚å ´",
        "speed_mmin": "é€Ÿåº¦(m/min)", "eta_hr": "ETA(hr)",
        "unit_cost_nt_per_m": "æˆæœ¬(NT$/m)", "profit_nt_per_m": "ç›ˆè™§(NT$/m)",
        "internal_carbon_nt_per_m": "å…§éƒ¨ç¢³(NT$/m)",
        "shelf_loss_nt_per_m": "åº«é½¡æå¤±(NT$/m)",
        "profit_with_carbon_and_shelf_nt_per_m": "å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)",
        "carbon_kgco2_per_m": "kgCO2/m",
        "shelf_risk": "åº«é½¡ç‹€æ…‹", "shelf_age_days": "åº«é½¡(å¤©)", "inventory_m": "åº«å­˜(m)",
        "exhaust_rh": "æ’é¢¨RH", "airflow_m3ph": "é¢¨é‡(m3/h)", "steam_kgph": "è’¸æ°£(kg/h)",
        "steam_util": "è’¸æ°£åˆ©ç”¨æ¯”"
    })

    st.dataframe(table, use_container_width=True, hide_index=True)

    st.markdown("#### ğŸ’¥ ä¸€éµæŒ‘å‡ºã€åœ¨ç‡’éŒ¢ã€çš„å·¥å–®")
    losers = view[view["profit_with_carbon_and_shelf_nt_per_m"] < 0].head(6)
    if len(losers):
        st.dataframe(losers[["line","flow_card","wo", "barcode", "otd", "profit_with_carbon_and_shelf_nt_per_m", "shelf_loss_nt_per_m", "carbon_kgco2_per_m", "exhaust_rh", "airflow_m3ph"]],
                     use_container_width=True, hide_index=True)
    else:
        st.success("âœ… ç›®å‰æ²’æœ‰å«ç¢³å¾Œç‚ºè² çš„å·¥å–®ï¼ˆDemo è³‡æ–™ï¼‰ã€‚")

    st.markdown("---")
    st.markdown("### ğŸ§µ å¸ƒæ–™æ™‚æ•ˆåº«å­˜ç›£æ§ï¼ˆShelf-life Managementï¼‰")
    st.write("ç•¶åº«é½¡è¶…éé–€æª»ï¼Œé¢æ¿è‡ªå‹•è½‰é»ƒ/ç´…ä¸¦è¨ˆå…¥ã€å“è³ªé¢¨éšªæå¤±ã€ï¼Œæé†’ç”Ÿç®¡å„ªå…ˆæ’ç”¢ã€‚")
    inv_view = inventory.sort_values(["shelf_age_days", "quality_loss_nt"], ascending=[False, False]).copy()

    # ä¿è­·ï¼šä¸åŒè³‡æ–™ä¾†æºæ¬„ä½å¯èƒ½ä¸é½Šï¼ˆä¾‹å¦‚çœŸå¯¦ WMS å¯èƒ½æ²’æœ‰ flow_cardï¼‰
    desired_cols = ["shelf_risk","shelf_age_days","roll_id","wo","flow_card","line","barcode","customer","inbound_date","qty_m","quality_loss_nt","quality_loss_nt_per_m"]
    existing_cols = [c for c in desired_cols if c in inv_view.columns]
    inv_show = inv_view[existing_cols].copy()

    # è‹¥ç¼º flow_card ä½† orders å¯å›å¡«ï¼ˆä»¥ wo å°æ‡‰ï¼‰
    if "flow_card" not in inv_show.columns:
        wo2fc = orders.set_index("wo")["flow_card"].to_dict() if "flow_card" in orders.columns else {}
        inv_show["flow_card"] = inv_show["wo"].map(lambda x: wo2fc.get(x, ""))
    inv_show = inv_show.rename(columns={
        "shelf_risk":"ç‹€æ…‹","shelf_age_days":"åº«é½¡(å¤©)","roll_id":"å·è™Ÿ","wo":"å·¥å–®","flow_card":"æµç¨‹å¡è™Ÿ","line":"ç·šåˆ¥",
        "barcode":"Barcode","customer":"å®¢æˆ¶","inbound_date":"å…¥åº«æ—¥","qty_m":"åº«å­˜(m)","quality_loss_nt":"å“è³ªé¢¨éšªæå¤±(NT$)","quality_loss_nt_per_m":"æå¤±(NT$/m)"
    })
    st.dataframe(inv_show, use_container_width=True, hide_index=True)

    st.markdown("#### ğŸ”¥ è¶…é½¡å· TOP10ï¼ˆæå¤±æœ€å¤§ï¼‰")
    aged_top = inventory[inventory["shelf_age_days"] > int(shelf_threshold_days)].copy()
    if len(aged_top) == 0:
        st.success("âœ… ç›®å‰æ²’æœ‰è¶…éé–€æª»çš„åº«å­˜å·ï¼ˆDemo è³‡æ–™ï¼‰ã€‚")
    else:
        aged_top = aged_top.sort_values(["quality_loss_nt", "shelf_age_days"], ascending=[False, False]).head(10)
        top_cols = [c for c in ["shelf_risk","shelf_age_days","quality_loss_nt","roll_id","wo","flow_card","line","customer","barcode","inbound_date","qty_m","quality_loss_nt_per_m"] if c in aged_top.columns]
        top_df = aged_top[top_cols].copy()
        if "flow_card" not in top_df.columns:
            wo2fc = orders.set_index("wo")["flow_card"].to_dict() if "flow_card" in orders.columns else {}
            top_df["flow_card"] = top_df["wo"].map(lambda x: wo2fc.get(x, ""))
        top_df = top_df.rename(columns={
            "shelf_risk":"ç‹€æ…‹","shelf_age_days":"åº«é½¡(å¤©)","quality_loss_nt":"å“è³ªé¢¨éšªæå¤±(NT$)",
            "roll_id":"å·è™Ÿ","wo":"å·¥å–®","flow_card":"æµç¨‹å¡è™Ÿ","line":"ç·šåˆ¥","customer":"å®¢æˆ¶",
            "barcode":"Barcode","inbound_date":"å…¥åº«æ—¥","qty_m":"åº«å­˜(m)","quality_loss_nt_per_m":"æå¤±(NT$/m)"
        })
        st.dataframe(top_df, use_container_width=True, hide_index=True)

    st.markdown("#### ğŸ§¾ å®¢æˆ¶åˆ¥åº«é½¡é¢¨éšªæ’è¡Œ")
    cust = inventory.copy()
    cust["is_over_threshold"] = cust["shelf_age_days"] > int(shelf_threshold_days)
    cust_rank = cust.groupby("customer", as_index=False).agg(
        rolls=("roll_id", "count"),
        over_rolls=("is_over_threshold", "sum"),
        over_ratio=("is_over_threshold", "mean"),
        max_age_days=("shelf_age_days", "max"),
        avg_age_days=("shelf_age_days", "mean"),
        total_loss_nt=("quality_loss_nt", "sum"),
        total_m=("qty_m", "sum"),
    )
    cust_rank["loss_nt_per_m"] = (cust_rank["total_loss_nt"] / cust_rank["total_m"].replace(0, np.nan)).fillna(0.0)
    # a simple "risk score" for ranking (auditable)
    cust_rank["risk_score"] = (cust_rank["over_ratio"] * 0.55 + (cust_rank["max_age_days"] / (int(shelf_threshold_days) + 20)) * 0.25 + (cust_rank["loss_nt_per_m"] / 2.0) * 0.20)
    cust_rank["risk_score"] = cust_rank["risk_score"].clip(0, 1.5)

    cust_rank = cust_rank.sort_values(["risk_score", "total_loss_nt"], ascending=[False, False])

    def cust_label(x: float) -> str:
        if x >= 0.85: return "ğŸ”´ é«˜"
        if x >= 0.55: return "ğŸŸ¡ ä¸­"
        return "ğŸŸ¢ ä½"

    cust_show = cust_rank.copy()
    cust_show["level"] = cust_show["risk_score"].apply(cust_label)
    cust_show = cust_show.rename(columns={
        "level":"é¢¨éšªç­‰ç´š","customer":"å®¢æˆ¶","risk_score":"é¢¨éšªåˆ†æ•¸","rolls":"å·æ•¸","over_rolls":"è¶…é½¡å·æ•¸","over_ratio":"è¶…é½¡å æ¯”",
        "max_age_days":"æœ€å¤§åº«é½¡(å¤©)","avg_age_days":"å¹³å‡åº«é½¡(å¤©)","total_loss_nt":"ç¸½å“è³ªæå¤±(NT$)","loss_nt_per_m":"æå¤±(NT$/m)","total_m":"ç¸½åº«å­˜(m)"
    })
    cust_show["è¶…é½¡å æ¯”"] = (cust_show["è¶…é½¡å æ¯”"] * 100.0).round(1).astype(str) + "%"
    show_cols = ["é¢¨éšªç­‰ç´š","å®¢æˆ¶","é¢¨éšªåˆ†æ•¸","å·æ•¸","è¶…é½¡å·æ•¸","è¶…é½¡å æ¯”","æœ€å¤§åº«é½¡(å¤©)","å¹³å‡åº«é½¡(å¤©)","ç¸½åº«å­˜(m)","æå¤±(NT$/m)","ç¸½å“è³ªæå¤±(NT$)"]
    show_cols = [c for c in show_cols if c in cust_show.columns]
    st.dataframe(cust_show[show_cols],
                 use_container_width=True, hide_index=True)

    st.markdown("#### ğŸš€ ä¸€éµæŠŠè¶…é½¡å·å°æ‡‰å·¥å–®é€å»ã€Œå„ªå…ˆæ’ç”¢ã€éšŠåˆ—ï¼ˆæ’åºæ¬Šé‡ï¼‰")
    with st.expander("è¨­å®šæ’åºæ¬Šé‡ï¼ˆå¯ç”¨æ–¼ææ¡ˆï¼šè¦å‰‡å¯ç¨½æ ¸ã€å¯èª¿åƒï¼‰", expanded=True):
        w_loss = st.slider("æ¬Šé‡ï¼šå“è³ªæå¤±ï¼ˆNT$ï¼‰", 0.0, 2.0, 1.0, 0.05)
        w_age = st.slider("æ¬Šé‡ï¼šåº«é½¡è¶…æ¨™ç¨‹åº¦", 0.0, 2.0, 0.9, 0.05)
        w_otd = st.slider("æ¬Šé‡ï¼šäº¤æœŸé¢¨éšªï¼ˆé€¾æœŸ/é¢¨éšªï¼‰", 0.0, 2.0, 0.8, 0.05)
        w_profit = st.slider("æ¬Šé‡ï¼šå«ç¢³+åº«é½¡ç‚ºè² ï¼ˆè¶Šè² è¶Šå„ªå…ˆï¼‰", 0.0, 2.0, 0.7, 0.05)

        st.caption("æ’åºåˆ†æ•¸ = w_loss*loss_norm + w_age*age_norm + w_otd*otd_norm + w_profit*neg_profit_normï¼ˆå…¨éƒ¨ 0~1 æ­£è¦åŒ–ï¼‰")

    # Build candidate WO list from inventory (only those over threshold)
    cand_rolls = inventory[inventory["shelf_age_days"] > int(shelf_threshold_days)].copy()
    if len(cand_rolls) == 0:
        st.info("ç›®å‰æ²’æœ‰è¶…é½¡å·ï¼Œå› æ­¤ä¸éœ€è¦æ¨é€å„ªå…ˆæ’ç”¢ã€‚")
    else:
        wo_agg = cand_rolls.groupby("wo", as_index=False).agg(
            total_quality_loss_nt=("quality_loss_nt", "sum"),
            max_shelf_age_days=("shelf_age_days", "max"),
            inventory_m=("qty_m", "sum"),
        )

        # Defensive: if upstream inventory schema differs, ensure inventory_m exists
        if "inventory_m" not in wo_agg.columns:
            if "qty_m" in cand_rolls.columns:
                wo_agg["inventory_m"] = cand_rolls.groupby("wo")["qty_m"].sum().values
            elif "length_m" in cand_rolls.columns:
                wo_agg["inventory_m"] = cand_rolls.groupby("wo")["length_m"].sum().values
            else:
                wo_agg["inventory_m"] = 0.0
        wo_view = orders.merge(wo_agg, on="wo", how="inner")
        wo_view["flow_card"] = wo_view["flow_card"].astype(str)
        wo_view["age_over"] = (wo_view["max_shelf_age_days"] - int(shelf_threshold_days)).clip(lower=0)

        # otd norm
        def otd_norm(label: str) -> float:
            if "ğŸ”´" in label: return 1.0
            if "ğŸŸ¡" in label: return 0.6
            return 0.2
        wo_view["otd_norm"] = wo_view["otd"].apply(otd_norm)

        # profit norm (only negative matters)
        wo_view["neg_profit"] = (-wo_view["profit_with_carbon_and_shelf_nt_per_m"]).clip(lower=0)
        # normalize features (0~1)
        def norm01(s: pd.Series) -> pd.Series:
            s2 = s.astype(float)
            mx = float(s2.max()) if len(s2) else 1.0
            mn = float(s2.min()) if len(s2) else 0.0
            if mx - mn < 1e-9:
                return pd.Series(np.zeros(len(s2)), index=s2.index)
            return (s2 - mn) / (mx - mn)

        wo_view["loss_norm"] = norm01(wo_view["total_quality_loss_nt"])
        wo_view["age_norm"] = norm01(wo_view["age_over"])
        wo_view["profit_norm"] = norm01(wo_view["neg_profit"])

        wo_view["score"] = (
            float(w_loss) * wo_view["loss_norm"]
            + float(w_age) * wo_view["age_norm"]
            + float(w_otd) * wo_view["otd_norm"]
            + float(w_profit) * wo_view["profit_norm"]
        )

        # Preview top candidates
        prev = wo_view.sort_values("score", ascending=False).head(8).copy()
        prev = prev.rename(columns={
            "line":"ç·šåˆ¥","flow_card":"æµç¨‹å¡è™Ÿ","wo":"å·¥å–®","customer":"å®¢æˆ¶","otd":"æº–äº¤","due":"äº¤æœŸ",
            "max_shelf_age_days":"æœ€å¤§åº«é½¡(å¤©)","total_quality_loss_nt":"ç¸½å“è³ªæå¤±(NT$)",
            "shelf_loss_nt_per_m":"åº«é½¡æå¤±(NT$/m)","profit_with_carbon_and_shelf_nt_per_m":"å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)",
            "score":"æ’åºåˆ†æ•¸"
        })
        st.dataframe(prev[["æ’åºåˆ†æ•¸","ç·šåˆ¥","æµç¨‹å¡è™Ÿ","å·¥å–®","å®¢æˆ¶","æº–äº¤","äº¤æœŸ","æœ€å¤§åº«é½¡(å¤©)","ç¸½å“è³ªæå¤±(NT$)","åº«é½¡æå¤±(NT$/m)","å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)"]],
                     use_container_width=True, hide_index=True)

        cbtn1, cbtn2 = st.columns([1,1])
        with cbtn1:
            push = st.button("ğŸ“¤ ä¸€éµæ¨é€ï¼šè¶…é½¡å·å°æ‡‰å·¥å–® â†’ å„ªå…ˆæ’ç”¢éšŠåˆ—", use_container_width=True)
        with cbtn2:
            clearq = st.button("ğŸ§¹ æ¸…ç©ºå„ªå…ˆæ’ç”¢éšŠåˆ—", use_container_width=True)

        if clearq:
            st.session_state.priority_queue = st.session_state.priority_queue.iloc[0:0].copy()
            st.success("å·²æ¸…ç©ºå„ªå…ˆæ’ç”¢éšŠåˆ—ã€‚")

        if push:
            now_ts = dt.datetime.now()
            q = st.session_state.priority_queue.copy()
            add = wo_view.copy()
            add["created_at"] = now_ts
            add["reasons"] = add.apply(
                lambda r: f"åº«é½¡è¶…æ¨™{int(r['age_over'])}å¤©ï½œæå¤±NT${r['total_quality_loss_nt']:.0f}ï½œ{r['otd']}",
                axis=1
            )
            add = add.rename(columns={
                "line":"line","flow_card":"flow_card","wo":"wo","customer":"customer","otd":"otd","due":"due",
                "max_shelf_age_days":"shelf_age_days","shelf_loss_nt_per_m":"shelf_loss_nt_per_m",
                "total_quality_loss_nt":"total_quality_loss_nt",
                "profit_with_carbon_and_shelf_nt_per_m":"profit_with_carbon_and_shelf_nt_per_m",
                "inventory_m":"inventory_m",
            })

            # Defensive: some columns may not exist depending on data source; create defaults
            if "inventory_m" not in add.columns:
                add["inventory_m"] = 0.0
            desired_cols = [
                "score","wo","flow_card","line","customer","otd","due",
                "shelf_age_days","shelf_loss_nt_per_m","total_quality_loss_nt",
                "profit_with_carbon_and_shelf_nt_per_m","inventory_m","created_at","reasons"
            ]
            desired_cols = [c for c in desired_cols if c in add.columns]
            add = add[desired_cols]

            # Defensive: concat requires uniquely named columns. Some upstream transforms
            # (especially when merging/renaming) can accidentally create duplicated
            # column names and trigger: InvalidIndexError: Reindexing only valid with uniquely valued Index objects.
            def _dedup_columns(df: pd.DataFrame) -> pd.DataFrame:
                df = df.copy()
                if df.columns.duplicated().any():
                    df = df.loc[:, ~df.columns.duplicated()].copy()
                return df

            q_base = q.drop(columns=["rank"], errors="ignore")
            q_base = _dedup_columns(q_base)
            add = _dedup_columns(add)

            q2 = pd.concat([q_base, add], ignore_index=True, sort=False)
            # de-dup by WO, keep the highest score
            q2 = q2.sort_values("score", ascending=False).drop_duplicates(subset=["wo"], keep="first")
            q2 = q2.sort_values("score", ascending=False).reset_index(drop=True)
            q2.insert(0, "rank", np.arange(1, len(q2) + 1))
            st.session_state.priority_queue = q2
            st.success(f"âœ… å·²æ¨é€ {len(add)} ç­†å·¥å–®åˆ°å„ªå…ˆæ’ç”¢éšŠåˆ—ï¼ˆè‡ªå‹•å»é‡ï¼‰ã€‚")

        if len(st.session_state.priority_queue):
            st.markdown("##### ğŸ“Œ ç›®å‰å„ªå…ˆæ’ç”¢éšŠåˆ—ï¼ˆç”±é«˜åˆ°ä½ï¼‰")
            qshow = st.session_state.priority_queue.copy()
            qshow["due"] = pd.to_datetime(qshow["due"]).dt.strftime("%Y-%m-%d %H:%M")
            qshow = qshow.rename(columns={
                "rank":"é †ä½","score":"åˆ†æ•¸","wo":"å·¥å–®","flow_card":"æµç¨‹å¡è™Ÿ","line":"ç·šåˆ¥","customer":"å®¢æˆ¶",
                "otd":"æº–äº¤","due":"äº¤æœŸ","shelf_age_days":"æœ€å¤§åº«é½¡(å¤©)","shelf_loss_nt_per_m":"åº«é½¡æå¤±(NT$/m)",
                "total_quality_loss_nt":"ç¸½å“è³ªæå¤±(NT$)","profit_with_carbon_and_shelf_nt_per_m":"å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)",
                "inventory_m":"åº«å­˜(m)","reasons":"åŸå› "
            })

            show_cols_q = ["é †ä½","åˆ†æ•¸","ç·šåˆ¥","æµç¨‹å¡è™Ÿ","å·¥å–®","å®¢æˆ¶","æº–äº¤","äº¤æœŸ","æœ€å¤§åº«é½¡(å¤©)","åº«å­˜(m)","ç¸½å“è³ªæå¤±(NT$)","å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)","åŸå› "]
            show_cols_q = [c for c in show_cols_q if c in qshow.columns]
            st.dataframe(qshow[show_cols_q], use_container_width=True, hide_index=True)

            # -----------------------------
            # Demo Export: PDF Schedule Suggestion
            # -----------------------------
            with st.expander("ğŸ“„ Demo ç‰ˆè¼¸å‡ºï¼šæ’ç¨‹å»ºè­°è¡¨ï¼ˆPDFï¼‰", expanded=False):
                if not _REPORTLAB_OK:
                    st.warning("æ­¤ç’°å¢ƒæœªå®‰è£ reportlabï¼Œç„¡æ³•è¼¸å‡º PDFã€‚è«‹å…ˆ pip install reportlab")
                else:
                    c1, c2 = st.columns([1,1])
                    with c1:
                        rate_m_per_hr = st.number_input("å‡è¨­ç”¢èƒ½ (m/hr)", min_value=50.0, max_value=5000.0, value=600.0, step=50.0)
                    with c2:
                        changeover_hr = st.number_input("åŒç·šæ›ç·šæ™‚é–“ (hr)", min_value=0.0, max_value=5.0, value=0.25, step=0.05)

                    gen_pdf = st.button("ç”Ÿæˆ PDFï¼ˆæ’ç¨‹å»ºè­°è¡¨ï¼‰", use_container_width=True)
                    if gen_pdf:
                        pdf_bytes = build_schedule_pdf_from_queue(
                            st.session_state.priority_queue,
                            now_ts=dt.datetime.now(),
                            rate_m_per_hr=float(rate_m_per_hr),
                            changeover_hr_same_line=float(changeover_hr),
                        )
                        st.session_state.last_sched_pdf = pdf_bytes
                        st.success("âœ… PDF å·²ç”Ÿæˆï¼Œå¯ç›´æ¥ä¸‹è¼‰ã€‚")

                    pdf_bytes = st.session_state.get("last_sched_pdf", b"")
                    if pdf_bytes:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è¼‰ï¼šæ’ç¨‹å»ºè­°è¡¨_å„ªå…ˆæ’ç”¢.pdf",
                            data=pdf_bytes,
                            file_name="æ’ç¨‹å»ºè­°è¡¨_å„ªå…ˆæ’ç”¢.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                        )

# -----------------------------
# Tab 2: Order View (aligned to on-site Page 1)
# -----------------------------
with tabs[1]:
    st.subheader("â‘¡ å·¥å–®é ï¼ˆå°é½Šç¾å ´ç¬¬ 1 é ï¼š8å€æº«åº¦/é¢¨è»Š/å¯¬åº¦ + æ±ºç­– KPIï¼‰")

    if show_on_site_refs:
        with st.expander("ğŸ–¼ï¸ å±•é–‹ï¼šç¾å ´åŸå§‹ç›£æ¸¬ç•«é¢ï¼ˆå…©é ï¼‰", expanded=False):
            c1, c2 = st.columns(2)
            img1 = "S__92315682_0.jpg"
            img2 = "S__92315681_0.jpg"
            with c1:
                if os.path.exists(img1):
                    st.image(img1, caption="ç¾å ´é  1ï¼šå·¥å–®/é…æ–¹/8å€è£½ç¨‹å³æ™‚")
                else:
                    st.info("æ‰¾ä¸åˆ°ç¾å ´é  1 åœ–æª”ï¼ˆè«‹æ”¾åœ¨åŒè³‡æ–™å¤¾ï¼‰ã€‚")
            with c2:
                if os.path.exists(img2):
                    st.image(img2, caption="ç¾å ´é  2ï¼šæ•´æ©Ÿé‹è½‰éƒ¨ä½ç‹€æ…‹")
                else:
                    st.info("æ‰¾ä¸åˆ°ç¾å ´é  2 åœ–æª”ï¼ˆè«‹æ”¾åœ¨åŒè³‡æ–™å¤¾ï¼‰ã€‚")

    pick = st.selectbox("é¸æ“‡å·¥å–®", orders["wo"].tolist())
    row = orders[orders["wo"] == pick].iloc[0]

    # Executive KPIs
    k1, k2, k3, k4, k5, k6 = st.columns(6)
    k1.metric("æµç¨‹å¡è™Ÿ", str(row["flow_card"]))
    k2.metric("ç·šåˆ¥", str(row["line"]))
    k3.metric("Barcode/Recipe", str(row["barcode"]))
    k4.metric("æº–äº¤", row["otd"], f"ETA {row['eta_hr']:.1f} hr")
    k5.metric("æ¯ç±³ç›ˆè™§ï¼ˆå«ç¢³+åº«é½¡ï¼‰", f"NT$ {row['profit_with_carbon_and_shelf_nt_per_m']:.2f}/m",
              f"åº«é½¡æå¤± {row['shelf_loss_nt_per_m']:.2f}/m")
    k6.metric("ç¢³å¼·åº¦", f"{row['carbon_kgco2_per_m']:.3f} kgCOâ‚‚/m", f"åº«é½¡ {int(row['shelf_age_days'])} å¤© {row['shelf_risk']}")

    st.write("---")

    if mode.startswith("ğŸ‘·"):
        # 8 zones: show like the on-site screen
        zcols = st.columns(8)
        for i in range(1, 9):
            with zcols[i-1]:
                st.markdown(f"**Zone {i}**")
                st.metric("æº«åº¦", f"{row[f'zone_temp_{i}']:.0f}Â°C")
                st.metric("é¢¨è»Š", f"{row[f'fan_hz_{i}']:.0f} Hz")
                st.metric("å¯¬åº¦", f"{row[f'width_mm_{i}']:.0f} mm")
    else:
        st.markdown("### âœ… é€™å¼µå·¥å–®çš„ã€ä¸‰å€‹é—œéµã€")
        drivers = []
        if row["exhaust_rh"] > 0.80:
            drivers.append(("æ’é¢¨RHåé«˜", "è’¸ç™¼é©…å‹•åŠ›ä¸‹é™ â†’ èƒ½è€—ä¸Šå‡"))
        if row["airflow_m3ph"] < 12500:
            drivers.append(("é¢¨é‡åä½", "æ’æ¿•èƒ½åŠ›ä¸è¶³ â†’ RHå®¹æ˜“ä¸Šå‡"))
        if row["steam_util"] > 1.05:
            drivers.append(("è’¸æ°£æ•ˆç‡åä½", "å¯èƒ½æ¼é¢¨/æ•£ç†±/ç–æ°´ä¸è‰¯"))
        if not drivers:
            drivers = [("ç‹€æ…‹è‰¯å¥½", "ç¶­æŒåƒæ•¸ä¸¦ç›£æ§æ¼‚ç§»")]

        for t, s in drivers[:3]:
            st.write(f"- **{t}**ï¼š{s}")

    st.write("---")
    b1, b2, b3, b4, b5, b6 = st.columns(6)
    b1.metric("å‰æ’é¢¨", f"{row['exhaust_front_hz']:.0f} Hz")
    b2.metric("å¾Œæ’é¢¨", f"{row['exhaust_back_hz']:.0f} Hz")
    b3.metric("å†·å»", f"{row['cooling_hz']:.0f} Hz")
    b4.metric("è’¸æ°£æµé‡", f"{row['steam_kgph']:.0f} kg/h", f"kWh_th/m {row['kwh_th_per_m_req']:.3f}")
    b5.metric("é¢¨é‡", f"{row['airflow_m3ph']:.0f} mÂ³/h", f"æ’é¢¨RH {row['exhaust_rh']*100:.1f}%")
    b6.metric("ç”¨é›»ä¼°ç®—", f"{row['power_kw']:.0f} kW", f"kWh_e/m {row['kwh_elec_per_m_est']:.3f}")

    # What-if panel (proposal killer feature)
    st.write("---")
    st.markdown("### ğŸ¯ Whatâ€‘ifï¼šèª¿ä¸€å€‹æ—‹éˆ•ï¼Œçœ‹éŒ¢èˆ‡ç¢³æ€éº¼è®Š")
    w1, w2, w3, w4 = st.columns(4)
    with w1:
        d_exh = st.slider("æ’é¢¨ +Hz", -10, 20, 5)
    with w2:
        d_air = st.slider("é¢¨é‡ +mÂ³/h", -5000, 8000, 2000, step=500)
    with w3:
        d_steam = st.slider("è’¸æ°£ +kg/h", -400, 700, 150, step=50)
    with w4:
        d_speed = st.slider("é€Ÿåº¦ +m/min", -8, 8, 1)

    # heuristic: increasing exhaust Hz & airflow reduces exhaust RH a bit (demo)
    rh_new = float(np.clip(row["exhaust_rh"] - 0.003 * d_exh - 0.000003 * d_air, 0.55, 0.95))
    airflow_new = float(max(5000.0, row["airflow_m3ph"] + d_air))
    steam_new = float(max(200.0, row["steam_kgph"] + d_steam))
    speed_new = float(max(10.0, row["speed_mmin"] + d_speed))

    ph_new = dryer_physics(
        speed_mmin=speed_new,
        steam_kgph=steam_new,
        airflow_m3ph=airflow_new,
        t_in_c=row["inlet_temp_c"],
        rh_in=row["inlet_rh"],
        t_out_c=row["exhaust_temp_c"],
        rh_out=rh_new,
        rho_air=rho_air,
        p_atm=p_atm,
        h_fg_kjkg=h_fg,
        h_steam_kjkg=h_steam,
        cp_air_kjkgk=cp_air,
        eta_base=eta_base,
    )

    # recompute deltas with the same cost settings
    m_per_hr_new = speed_new * 60.0
    kwh_e_new = float((row["power_kw"] / max(m_per_hr_new, 1e-6)))
    energy_nt_new = kwh_e_new * elec_price + ph_new["kwh_th_per_m_req"] * steam_price_proxy
    labor_nt_new = labor_hr / max(m_per_hr_new, 1e-6)
    machine_nt_new = machine_hr / max(m_per_hr_new, 1e-6)
    unit_cost_new = energy_nt_new + labor_nt_new + machine_nt_new + overhead_m
    carbon_new = kwh_e_new * ef_elec + ph_new["kwh_th_per_m_req"] * ef_steam
    carbon_cost_new = (carbon_new / 1000.0) * internal_carbon
    profit_new = row["sell_price_nt_per_m"] - unit_cost_new
    profit_carbon_new = row["sell_price_nt_per_m"] - (unit_cost_new + carbon_cost_new)

    base_profit = float(row["profit_nt_per_m"])
    base_profit_c = float(row["profit_with_carbon_nt_per_m"])
    base_c = float(row["carbon_kgco2_per_m"])

    r1, r2, r3, r4 = st.columns(4)
    r1.metric("æ’é¢¨RHï¼ˆä¼°ï¼‰", f"{rh_new*100:.1f}%", f"åŸ {row['exhaust_rh']*100:.1f}%")
    r2.metric("å«ç¢³ç›ˆè™§ï¼ˆæ–°ï¼‰", f"NT$ {profit_carbon_new:.2f}/m", f"Î” {profit_carbon_new-base_profit_c:+.2f}")
    r3.metric("ç¢³å¼·åº¦ï¼ˆæ–°ï¼‰", f"{carbon_new:.3f} kgCOâ‚‚/m", f"Î” {carbon_new-base_c:+.3f}")
    r4.metric("è’¸æ°£kWh/mï¼ˆæ–°ï¼‰", f"{ph_new['kwh_th_per_m_req']:.3f}", f"Î” {ph_new['kwh_th_per_m_req']-row['kwh_th_per_m_req']:+.3f}")

    if show_formulas:
        with st.expander("ğŸ“ å±•é–‹ï¼šç‰©ç†æ¨¡å‹å…¬å¼ + Tag å°æ‡‰", expanded=False):
            st.markdown("**Tag å°æ‡‰ï¼ˆç¾å ´å·²å…·å‚™ï¼‰**ï¼šè’¸æ°£æµé‡ / æ’é¢¨æº«æ¿•åº¦ / é¢¨é‡ / å¸ƒé€Ÿ")
            render_formulas()

# -----------------------------
# Tab 3: Asset view
# -----------------------------
with tabs[2]:
    st.subheader("â‘¢ è¨­å‚™é ï¼ˆå°é½Šç¾å ´ç¬¬ 2 é ï¼šæ•´æ©Ÿéƒ¨ä½ç‹€æ…‹ â†’ å½±éŸ¿æº–äº¤/ç›ˆè™§/èƒ½è€—ï¼‰")

    pick = st.selectbox("é¸æ“‡å·¥å–®ï¼ˆç”¨ç•¶ä¸‹å·¥å–®å¸¶å‡ºè¨­å‚™å½±éŸ¿ï¼‰", orders["wo"].tolist(), key="asset_pick")
    row = orders[orders["wo"] == pick].iloc[0]
    cards = build_asset_cards(row)

    for _, r in cards.iterrows():
        with st.container(border=True):
            c1, c2, c3, c4 = st.columns([2.3, 1.0, 1.0, 1.0])
            c1.markdown(f"## {r['health']} {r['subsystem']}")
            # impact scoring (proposal-friendly)
            impact_otd = "ğŸŸ¡" if row["otd"] != "ğŸŸ¢ æº–äº¤" else "ğŸŸ¢"
            impact_profit = "ğŸ”´" if row["profit_with_carbon_nt_per_m"] < 0 else ("ğŸŸ¡" if row["profit_with_carbon_nt_per_m"] < 1 else "ğŸŸ¢")
            impact_energy = "ğŸ”´" if row["kwh_th_per_m_req"] > np.percentile(orders["kwh_th_per_m_req"], 70) else ("ğŸŸ¡" if row["kwh_th_per_m_req"] > np.percentile(orders["kwh_th_per_m_req"], 40) else "ğŸŸ¢")
            c2.metric("æº–äº¤å½±éŸ¿", impact_otd)
            c3.metric("ç›ˆè™§å½±éŸ¿", impact_profit)
            c4.metric("èƒ½è€—å½±éŸ¿", impact_energy)

            k1, k2, k3 = st.columns(3)
            if r["kpi1"] == "exhaust_rh":
                k1.write(f"**{r['kpi1']}**ï¼š{r['v1']*100:.1f}%")
            else:
                k1.write(f"**{r['kpi1']}**ï¼š{r['v1']:.2f}")
            k2.write(f"**{r['kpi2']}**ï¼š{r['v2']:.2f}")

            hint = "å»ºè­°ï¼šç¶­æŒç›£æ§ã€‚"
            if r["subsystem"] == "Exhaust / Dehumid" and row["exhaust_rh"] > 0.80:
                hint = "å»ºè­°ï¼šæé«˜æ’é¢¨/é™¤æ¿•ã€æª¢æŸ¥æ’é¢¨é¢¨é“é˜»å¡ã€é™ä½æ¼é¢¨ã€‚"
            elif r["subsystem"] == "Fan & Airflow" and row["airflow_m3ph"] < 12500:
                hint = "å»ºè­°ï¼šæª¢æŸ¥é¢¨è»ŠVFD/çš®å¸¶/æ¿¾ç¶²å£“å·®ï¼›é¢¨é‡ä¸è¶³æœƒè®“RHä¸Šå‡ã€‚"
            elif r["subsystem"] == "Steam / Heater" and row["steam_util"] > 1.05:
                hint = "å»ºè­°ï¼šæª¢æŸ¥è’¸æ°£å£“/ç–æ°´å™¨ã€ä¿æº«ã€æ¼é¢¨ï¼›é¿å…ç†±è¢«æ’é¢¨å¸¶èµ°ã€‚"
            elif r["subsystem"] == "Chain / Tension":
                widths = [row[f"width_mm_{i}"] for i in range(1, 9)]
                if float(np.std(widths)) > 4:
                    hint = "å»ºè­°ï¼šå¯¬åº¦æ³¢å‹•åå¤§ï¼Œæª¢æŸ¥éˆæ¢/å¤¾å…·ç£¨è€—ã€å¼µåŠ›è¨­å®šã€å°å¸ƒã€‚"
            st.caption(hint)

# -----------------------------
# Tab 4: Event timeline
# -----------------------------

with tabs[3]:
    st.subheader("â‘£ äº‹ä»¶æ™‚é–“ç·šï¼šæŠŠã€è¨­å‚™ç•°å¸¸ã€ç¿»è­¯æˆã€å·¥å–®æç›ŠåŸå› ã€ï¼ˆPLC + æ©Ÿå™¨ç‹—ï¼‰")

    # init robotdog demo once (PoC mode: CSV/JSON can replace generator)
    if "robotdog_demo" not in st.session_state:
        try:
            lines = orders["line"].unique().tolist()
        except Exception:
            lines = ["LINE-A","LINE-B","LINE-C","LINE-D"]
        st.session_state.robotdog_demo = generate_demo_robotdog_runs(lines=lines)

    robot_obs = st.session_state.robotdog_demo

    pick = st.selectbox("é¸æ“‡å·¥å–®", orders["wo"].tolist(), key="event_pick")
    row = orders[orders["wo"] == pick].iloc[0]
    line = str(row["line"])

    # 1) PLC/physics rule events
    events_plc = detect_events(row)
    ev_plc = pd.DataFrame(events_plc) if events_plc else pd.DataFrame(columns=["ts","severity","event","subsystem","explain","impact_nt_per_m"])
    if len(ev_plc):
        ev_plc["line"] = line
        ev_plc["evidence_uri"] = "plc://"

    # 2) Robot dog events (filtered)
    win_hours = st.slider("å·¡æª¢äº‹ä»¶å›æº¯(å°æ™‚)", 1, 72, 6)
    tmin = dt.datetime.now() - dt.timedelta(hours=int(win_hours))
    obs_line = robot_obs[(robot_obs["line"] == line) & (robot_obs["ts"] >= tmin)].copy()
    ev_robot = robotdog_to_events(obs_line)

    # merge
    ev_all = pd.concat([ev_plc, ev_robot], ignore_index=True, sort=False).sort_values("ts", ascending=True)

    if len(ev_all) == 0:
        st.success("âœ… ç›®å‰æœªåµæ¸¬åˆ°äº‹ä»¶ï¼ˆPLC + æ©Ÿå™¨ç‹—ï¼‰ã€‚")
    else:
        show_cols = ["ts","severity","event","subsystem","explain","impact_nt_per_m","line","evidence_uri"]
        st.dataframe(ev_all[show_cols], use_container_width=True, hide_index=True)

        total_impact = float(ev_all["impact_nt_per_m"].sum()) if "impact_nt_per_m" in ev_all.columns else 0.0
        st.metric("é ä¼°æç›Šå½±éŸ¿ï¼ˆæ¯ç±³ï¼‰", f"NT$ {total_impact:.2f}/m")

        st.markdown("### âœ… å»ºè­°å‹•ä½œï¼ˆæŒ‰å½±éŸ¿æ’åºï¼‰")
        ev2 = ev_all.sort_values("impact_nt_per_m")
        for _, e in ev2.iterrows():
            st.write(f"- {e['severity']} **{e['event']}**ï¼ˆ{e['subsystem']}ï¼‰[{e.get('evidence_uri','')}]ï¼š{e['explain']}ï½œå½±éŸ¿â‰ˆ {float(e['impact_nt_per_m']):.2f} NT$/m")
with tabs[4]:
    st.subheader("â‘¤ AR çœ¼é¡ï¼ˆç¾å ´å³æ™‚ç–ŠåŠ ï¼‰")

    st.markdown("""
ğŸ•¶ï¸ **AR ç¾å ´æƒ…å¢ƒ**
- æ“ä½œäººå“¡æˆ´ä¸Š AR çœ¼é¡ï¼ˆHoloLens / RealWearï¼‰
- çœ‹å‘å®šå‹æ©Ÿæ™‚ï¼Œå³æ™‚ç–ŠåŠ ï¼š
  - å·¥å–® / æº–äº¤
  - æ¯ç±³ç›ˆè™§ï¼ˆå«ç¢³ï¼‰
  - é—œéµéƒ¨ä½ç‹€æ…‹ï¼ˆæ’é¢¨ / é¢¨é‡ / è’¸æ°£ï¼‰
""")

    pick = st.selectbox("æ¨¡æ“¬ AR çœ¼é¡ç›®å‰çœ‹åˆ°çš„å·¥å–®", orders["wo"].tolist(), key="ar_pick")
    row = orders[orders["wo"] == pick].iloc[0]

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å·¥å–®", row["wo"])
    c2.metric("æº–äº¤", row["otd"])
    c3.metric("æ¯ç±³ç›ˆè™§ï¼ˆå«ç¢³ï¼‰", f"NT$ {row['profit_with_carbon_nt_per_m']:.2f}/m",
              "ğŸ”´ ç‡’éŒ¢" if row["profit_with_carbon_nt_per_m"] < 0 else "ğŸŸ¢ æ­£å¸¸")
    c4.metric("ç¢³å¼·åº¦", f"{row['carbon_kgco2_per_m']:.3f} kgCOâ‚‚/m")

    st.write("---")
    d1, d2, d3 = st.columns(3)
    d1.metric("æ’é¢¨ RH", f"{row['exhaust_rh']*100:.1f}%", "âš  åé«˜" if row["exhaust_rh"] > 0.8 else "æ­£å¸¸")
    d2.metric("é¢¨é‡", f"{row['airflow_m3ph']:.0f} mÂ³/h", "âš  åä½" if row["airflow_m3ph"] < 12500 else "æ­£å¸¸")
    d3.metric("è’¸æ°£åˆ©ç”¨æ¯”", f"{row['steam_util']:.2f}", "âš  æµªè²»" if row["steam_util"] > 1.1 else "æ­£å¸¸")

    if row["profit_with_carbon_nt_per_m"] < 0:
        st.error("âŒ å³æ™‚åˆ¤æ–·ï¼šé€™ä¸€ç±³æ­£åœ¨ç‡’éŒ¢ â†’ å»ºè­°ç«‹å³èª¿æ•´æ’é¢¨/é¢¨é‡/é€Ÿåº¦")
    else:
        st.success("âœ… å³æ™‚åˆ¤æ–·ï¼šè£½ç¨‹ç©©å®š")

# -----------------------------
# Tab 6: AR + Real-time margin
# -----------------------------
with tabs[5]:
    st.subheader("â‘¥ ARï¼ˆæ‡‰æ”¶å¸³æ¬¾ï¼‰+ å³æ™‚æˆæœ¬ç›ˆè™§ï¼ˆæŠŠã€æ”¶æ¬¾ã€è·Ÿã€å·¥å–®æç›Šã€ç¶åœ¨ä¸€èµ·ï¼‰")

    c1, c2, c3, c4 = st.columns(4)
    total_ar = float(ar["ar_amount_nt"].sum())
    overdue_ar = float(ar.loc[ar["days_overdue"] > 0, "ar_amount_nt"].sum())
    high_risk_ar = float(ar.loc[ar["risk_score"] >= 0.70, "ar_amount_nt"].sum())
    ar_profit = float(ar["ar_profit_with_carbon_nt"].sum())

    c1.metric("AR ç¸½é¡", f"NT$ {total_ar:,.0f}")
    c2.metric("é€¾æœŸ AR", f"NT$ {overdue_ar:,.0f}", f"{(overdue_ar/max(total_ar,1e-6))*100:.1f}%")
    c3.metric("é«˜é¢¨éšª AR", f"NT$ {high_risk_ar:,.0f}", f"{(high_risk_ar/max(total_ar,1e-6))*100:.1f}%")
    c4.metric("AR å°æ‡‰ã€å«ç¢³ç›ˆè™§ã€", f"NT$ {ar_profit:,.0f}")

    st.markdown("---")
    f1, f2, f3 = st.columns([1.2, 1.0, 1.2])
    with f1:
        cust = st.selectbox("å®¢æˆ¶", ["ALL"] + sorted(ar["customer"].unique().tolist()))
    with f2:
        bucket = st.selectbox("å¸³é½¡", ["ALL", "current", "0-7", "1-30", "90+"])
    with f3:
        risk = st.selectbox("é¢¨éšª", ["ALL", "ğŸŸ¢ æ­£å¸¸", "ğŸŸ¡ æ³¨æ„", "ğŸ”´ é«˜é¢¨éšª"])

    view = ar.copy()
    if cust != "ALL":
        view = view[view["customer"] == cust]
    if bucket != "ALL":
        view = view[view["bucket"] == bucket]
    if risk != "ALL":
        view = view[view["risk"] == risk]

    view = view.sort_values(["risk_score", "days_overdue", "ar_amount_nt"], ascending=[False, False, False])

    show = view[[
        "risk", "customer", "market", "invoice_no", "wo", "barcode",
        "invoice_date", "due_date", "days_overdue",
        "invoice_amount_nt", "paid_amount_nt", "ar_amount_nt",
        "profit_with_carbon_and_shelf_nt_per_m", "shelf_loss_nt_per_m", "carbon_kgco2_per_m",
        "ar_profit_with_carbon_nt"
    ]].copy()

    show = show.rename(columns={
        "risk": "é¢¨éšª", "customer": "å®¢æˆ¶", "market": "å¸‚å ´", "invoice_no": "ç™¼ç¥¨è™Ÿ",
        "wo": "å·¥å–®", "barcode": "Barcode",
        "invoice_date": "é–‹ç«‹æ—¥", "due_date": "åˆ°æœŸæ—¥", "days_overdue": "é€¾æœŸ(å¤©)",
        "invoice_amount_nt": "ç™¼ç¥¨é‡‘é¡(NT$)", "paid_amount_nt": "å·²æ”¶(NT$)", "ar_amount_nt": "æœªæ”¶AR(NT$)",
        "profit_with_carbon_and_shelf_nt_per_m": "å«ç¢³+åº«é½¡ç›ˆè™§(NT$/m)", "shelf_loss_nt_per_m":"åº«é½¡æå¤±(NT$/m)", "carbon_kgco2_per_m": "kgCO2/m",
        "ar_profit_with_carbon_nt": "ARå°æ‡‰å«ç¢³ç›ˆè™§(NT$)"
    })

    # ---- Customer level: Produced cloth x AR linkage (management view)
    if cust != "ALL":
        oc = orders[orders["customer"] == cust].copy()
        produced_m = float(oc["done_m"].sum())
        produced_profit = float((oc["done_m"] * oc["profit_with_carbon_and_shelf_nt_per_m"]).sum())
        produced_carbon_t = float((oc["done_m"] * oc["carbon_kgco2_per_m"]).sum() / 1000.0)

        ac = ar[ar["customer"] == cust].copy()
        ar_amt = float(ac["ar_amount_nt"].sum())
        overdue_amt = float(ac.loc[ac["days_overdue"] > 0, "ar_amount_nt"].sum())
        risk_avg = float(ac["risk_score"].mean()) if len(ac) else 0.0

        st.markdown("### ğŸ”— å·²ç”Ÿç”¢çš„å¸ƒ Ã— æœªæ”¶å›çš„éŒ¢ï¼ˆåŒä¸€å€‹å®¢æˆ¶ï¼‰")
        s1, s2, s3, s4 = st.columns(4)
        s1.metric("å·²ç”Ÿç”¢(ç±³)", f"{produced_m:,.0f}")
        s2.metric("å°æ‡‰å«ç¢³+åº«é½¡ç›ˆè™§(NT$)", f"{produced_profit:,.0f}")
        s3.metric("æœªæ”¶ AR(NT$)", f"{ar_amt:,.0f}", f"é€¾æœŸ {overdue_amt:,.0f}")
        s4.metric("AR é¢¨éšªå¹³å‡", f"{risk_avg:.2f}", "ğŸ”´" if risk_avg >= 0.70 else ("ğŸŸ¡" if risk_avg >= 0.45 else "ğŸŸ¢"))

        st.caption(f"ç¢³é‡ï¼ˆä¼°ï¼‰ï¼š{produced_carbon_t:.2f} tCOâ‚‚eï¼ˆä»¥ kgCOâ‚‚/m Ã— å·²ç”Ÿç”¢ç±³æ•¸ä¼°ç®—ï¼‰")

    st.dataframe(show, use_container_width=True, hide_index=True)

    st.markdown("### ğŸ“Œ AR é¢¨éšªèˆ‡æ”¹å–„å»ºè­°ï¼ˆææ¡ˆç”¨ï¼‰")
    st.write("- æŠŠã€é€¾æœŸ/é«˜é¢¨éšª ARã€èˆ‡ã€å«ç¢³å¾Œä»ç‚ºè² çš„å·¥å–®ã€äº¤å‰ï¼Œèƒ½å¿«é€Ÿå®šä½ï¼š**å“ªäº›è¨‚å–®åœ¨ç‡’éŒ¢ä¸”å›æ¬¾æ…¢**ã€‚")
    st.write("- å° EUï¼šå¯æŠŠ kgCOâ‚‚/m è½‰æˆ CBAM æˆæœ¬æƒ…å¢ƒï¼Œåšã€å ±åƒ¹/æ¢æ¬¾/èè³‡ã€èª¿æ•´ã€‚")
    st.write("- ä¸Šç·šå¾Œï¼šAR ç›´æ¥ç”± ERPï¼ˆInvoice/Receiptï¼‰é¤µå…¥ï¼›å·¥å–®æç›Šèˆ‡ç¢³æˆæœ¬ç”± MES/PLC å³æ™‚æ›´æ–°ã€‚")

    with st.expander("â¬‡ï¸ åŒ¯å‡ºï¼ˆCSVï¼‰", expanded=False):
        csv = show.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è¼‰ AR + å«ç¢³ç›ˆè™§æ¸…å–® CSV", data=csv, file_name="AR_profit_carbon_demo.csv", mime="text/csv")




with tabs[7]:
    st.subheader("â‘§ æ©Ÿå™¨ç‹—å·¡æª¢ï¼ˆRobot Dogï¼‰â€” å®šå‹æ©Ÿå››ç·šæ™ºæ…§å·¡æª¢æ•´åˆï¼ˆPoC: CSVï¼‰")
    st.caption("å‡ç´šç‰ˆï¼šRobotDog å·¡æª¢äº‹ä»¶ â†’ è‡ªå‹•ç”Ÿæˆç¶­ä¿®å·¥å–®ï¼ˆå« PR/POï¼‰ï¼Œä¸¦å¯é»é–‹ evidenceï¼ˆåœ–/ç†±åƒ/éŸ³æª”ï¼‰ã€‚")

    # -----------------------------
    # PoC CSV ingestion
    # -----------------------------
    def load_robotdog_csv(uploaded) -> pd.DataFrame:
        df = pd.read_csv(uploaded)
        # normalize column names
        df.columns = [c.strip() for c in df.columns]
        if "ts" in df.columns:
            df["ts"] = pd.to_datetime(df["ts"], errors="coerce")
        elif "timestamp" in df.columns:
            df["ts"] = pd.to_datetime(df["timestamp"], errors="coerce")
        else:
            # fallback: now
            df["ts"] = dt.datetime.now()

        # required defaults
        for c, default in [
            ("line", "LINE-A"),
            ("subsystem", "Fan & Airflow"),
            ("anomaly_type", "UNKNOWN"),
            ("severity", "ğŸŸ¢"),
            ("ir_max_c", 0.0),
            ("noise_db", 0.0),
            ("vib_rms", 0.0),
            ("gas_ppm", 0.0),
            ("confidence", 0.75),
            ("evidence_uri", ""),
        ]:
            if c not in df.columns:
                df[c] = default

        # allow evidence columns (optional)
        for c in ["evidence_image", "evidence_thermal", "evidence_audio"]:
            if c not in df.columns:
                df[c] = ""

        # coerce dtypes
        for c in ["ir_max_c","noise_db","vib_rms","gas_ppm","confidence"]:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)

        # sort
        df = df.dropna(subset=["ts"]).sort_values("ts").reset_index(drop=True)
        return df

    st.markdown("### 1) è³‡æ–™æ¥å…¥ï¼ˆCSVï¼‰")
    st.write("ä¸Šå‚³ RobotDog CSVï¼ˆå¯ç”±æ©Ÿå™¨ç‹—æ¯æ¬¡å·¡æª¢è¼¸å‡ºï¼‰ã€‚è‹¥æœªä¸Šå‚³ï¼Œä½¿ç”¨å…§å»º Demoã€‚")
    csv_up = st.file_uploader("ä¸Šå‚³ RobotDog å·¡æª¢ CSV", type=["csv"], key="rd_csv")

    # -----------------------------
    # Evidence ingestion (upload files)
    # -----------------------------
    st.markdown("### 2) Evidence ä¸Šå‚³ï¼ˆåœ– / ç†±åƒ / éŸ³æª”ï¼‰")
    st.write("å¯ä¸Šå‚³å¤šå€‹æª”æ¡ˆã€‚CSV çš„ evidence_image/evidence_thermal/evidence_audio æ¬„ä½å¡«æª”åå³å¯å°æ‡‰ã€‚")
    ev_files = st.file_uploader(
        "ä¸Šå‚³ evidence æª”æ¡ˆï¼ˆjpg/png/webp/wav/mp3ï¼‰",
        type=["jpg","jpeg","png","webp","wav","mp3","m4a"],
        accept_multiple_files=True,
        key="rd_ev_files"
    )
    if "rd_evidence_store" not in st.session_state:
        st.session_state.rd_evidence_store = {}  # filename -> bytes
    if ev_files:
        for f in ev_files:
            st.session_state.rd_evidence_store[f.name] = f.getvalue()

    # -----------------------------
    # Load observations
    # -----------------------------
    if csv_up is not None:
        try:
            obs = load_robotdog_csv(csv_up)
            st.success(f"âœ… å·²è¼‰å…¥ CSVï¼š{len(obs)} ç­†å·¡æª¢è§€æ¸¬")
        except Exception as e:
            st.error(f"CSV è§£æå¤±æ•—ï¼š{e}")
            obs = pd.DataFrame()
    else:
        if "robotdog_demo" not in st.session_state:
            try:
                lines = orders["line"].unique().tolist()
            except Exception:
                lines = ["LINE-A","LINE-B","LINE-C","LINE-D"]
            st.session_state.robotdog_demo = generate_demo_robotdog_runs(lines=lines)
            # add evidence columns for demo
            st.session_state.robotdog_demo["evidence_image"] = ""
            st.session_state.robotdog_demo["evidence_thermal"] = ""
            st.session_state.robotdog_demo["evidence_audio"] = ""
        obs = st.session_state.robotdog_demo.copy()

    if len(obs) == 0:
        st.info("å°šç„¡å·¡æª¢è³‡æ–™ã€‚è«‹ä¸Šå‚³ CSV æˆ–ä½¿ç”¨ Demoã€‚")
        st.stop()

    # -----------------------------
    # Filters
    # -----------------------------
    c1, c2, c3, c4 = st.columns([1.0, 1.0, 1.6, 1.0])
    with c1:
        line_pick = st.selectbox("ç·šåˆ¥", ["ALL"] + sorted(obs["line"].unique().tolist()), key="rd_line2")
    with c2:
        sev_pick = st.selectbox("åš´é‡åº¦", ["ALL","ğŸ”´","ğŸŸ¡","ğŸŸ¢"], key="rd_sev2")
    with c3:
        q = st.text_input("æœå°‹ï¼ˆanomaly/subsystemï¼‰", "", key="rd_q2")
    with c4:
        hrs = st.number_input("å›æº¯(å°æ™‚)", min_value=1, max_value=168, value=24, step=1, key="rd_hrs2")

    tmin = dt.datetime.now() - dt.timedelta(hours=int(hrs))
    view = obs[obs["ts"] >= tmin].copy()

    if line_pick != "ALL":
        view = view[view["line"] == line_pick]
    if sev_pick != "ALL":
        view = view[view["severity"] == sev_pick]
    if q:
        ql = q.lower()
        view = view[
            view["anomaly_type"].astype(str).str.lower().str.contains(ql) |
            view["subsystem"].astype(str).str.lower().str.contains(ql)
        ]

    s1, s2, s3, s4 = st.columns(4)
    s1.metric("å·¡æª¢äº‹ä»¶æ•¸", f"{len(view)}")
    s2.metric("ğŸ”´ åš´é‡", f"{int((view['severity']=='ğŸ”´').sum())}")
    s3.metric("ğŸŸ¡ è­¦å‘Š", f"{int((view['severity']=='ğŸŸ¡').sum())}")
    s4.metric("å¹³å‡ä¿¡å¿ƒ", f"{float(view['confidence'].mean() if len(view) else 0):.2f}")

    st.markdown("### 3) å·¡æª¢è§€æ¸¬åˆ—è¡¨")
    st.dataframe(
        view.sort_values(["severity","confidence","ts"], ascending=[True, False, False]),
        use_container_width=True,
        hide_index=True
    )

    # -----------------------------
    # Findings -> Events
    # -----------------------------
    st.markdown("### 4) Findings â†’ äº‹ä»¶ï¼ˆå¯æ±ºç­–ï¼‰")
    ev = robotdog_to_events(view)
    if len(ev) == 0:
        st.info("æ­¤æ™‚é–“çª—å…§ç„¡å·¡æª¢äº‹ä»¶ã€‚")
        st.stop()

    # Mapping: anomaly -> suggested action & PR items
    ACTION_MAP = {
        "STEAM_LEAK": ("æª¢æŸ¥è’¸æ°£ç®¡è·¯/é–¥ä»¶ï¼Œç¢ºèªæ´©æ¼é»ä¸¦æ›´æ›å¢Šç‰‡/é–¥ä»¶", [("è’¸æ°£ç®¡å¢Šç‰‡/å¯†å°ä»¶", 2, 800), ("è€ç†±æŸå¸¶/ä¿æº«ææ–™", 1, 1200)]),
        "DUCT_BLOCKAGE": ("æª¢æŸ¥é¢¨é“/æ¿¾ç¶²å µå¡ï¼Œå®‰æ’æ¸…æ½”èˆ‡æ›´æ›æ¿¾æ", [("æ¿¾ç¶²/æ¿¾æ", 4, 600), ("æ¸…æ½”è€—æ", 1, 500)]),
        "BEARING_NOISE": ("è»¸æ‰¿ç•°éŸ³ï¼šæ½¤æ»‘/æ ¡æ­£ï¼Œå¿…è¦æ™‚æ›´æ›è»¸æ‰¿", [("è»¸æ‰¿", 2, 2500), ("æ½¤æ»‘è„‚", 1, 450)]),
        "ABNORMAL_VIB": ("éœ‡å‹•ç•°å¸¸ï¼šæª¢æŸ¥ä¸å¹³è¡¡/é¬†å‹•ï¼Œæ ¡æ­£ä¸¦ç·Šå›º", [("å›ºå®šèºæ “/æ­¢é¬†", 1, 300), ("å‹•å¹³è¡¡/æ ¡æ­£æœå‹™", 1, 6000)]),
        "BELT_SLIP": ("çš®å¸¶æ‰“æ»‘ï¼šèª¿æ•´å¼µåŠ›/æ›´æ›çš®å¸¶", [("å‚³å‹•çš®å¸¶", 2, 1800)]),
        "HOTSPOT_PANEL": ("é›»æ§ç®±ç†±é»ï¼šæª¢æŸ¥æ¥é»/è² è¼‰ï¼Œç·Šå›ºä¸¦åšç†±å½±åƒè¤‡æ¸¬", [("ç«¯å­/æ¥è§¸å™¨", 1, 3500)]),
        "OIL_LEAK": ("æ¼æ²¹ï¼šç¢ºèªæ²¹å°/ç®¡ä»¶ï¼Œæ¸…æ½”ä¸¦æ›´æ›æ²¹å°", [("æ²¹å°", 2, 900), ("å¸æ²¹æ£‰/æ¸…æ½”è€—æ", 1, 400)]),
        "OBSTACLE": ("å®‰å…¨ï¼šæ¸…é™¤èµ°é“éšœç¤™ç‰©ä¸¦åŠ å¼·å€åŸŸæ¨™ç¤º", [("å®‰å…¨è­¦ç¤ºè²¼/åœæ¬„", 1, 800)]),
        "UNKNOWN": ("è«‹å·¥ç¨‹å¸«ç¾å ´è¤‡æ ¸ï¼Œå¿…è¦æ™‚åŠ æ¸¬", [("ç¾å ´æª¢ä¿®å·¥æ™‚", 1, 0)]),
    }

    def event_to_ticket_row(r: pd.Series) -> dict:
        at = str(r["event"])
        action, items = ACTION_MAP.get(at, ACTION_MAP["UNKNOWN"])
        # priority: ğŸ”´ P1, ğŸŸ¡ P2, ğŸŸ¢ P3
        prio = {"ğŸ”´":"P1", "ğŸŸ¡":"P2", "ğŸŸ¢":"P3"}.get(str(r["severity"]), "P3")
        est_downtime = {"P1": 60, "P2": 30, "P3": 10}[prio]
        est_cost = 0.0
        for _, qty, unit in items:
            est_cost += float(qty) * float(unit)
        return {
            "ticket_id": "",
            "created_ts": dt.datetime.now(),
            "line": str(r.get("line","LINE-A")),
            "subsystem": str(r.get("subsystem","")),
            "issue": at,
            "severity": str(r.get("severity","ğŸŸ¢")),
            "priority": prio,
            "suggested_action": action,
            "impact_nt_per_m": float(r.get("impact_nt_per_m", 0.0)),
            "est_downtime_min": int(est_downtime),
            "est_material_cost_nt": float(est_cost),
            "status": "OPEN",
            "pr_id": "",
            "po_id": "",
            "evidence_image": str(r.get("evidence_image","")),
            "evidence_thermal": str(r.get("evidence_thermal","")),
            "evidence_audio": str(r.get("evidence_audio","")),
            "evidence_uri": str(r.get("evidence_uri","")),
        }

    # Attach confidence/signals/evidence from observations to event rows (best-effort)
    # In production, use observation_id / run_id for exact linkage.
    tmp_cols = ["ts","line","anomaly_type","confidence","ir_max_c","noise_db","vib_rms","gas_ppm","evidence_uri",
                "evidence_image","evidence_thermal","evidence_audio"]
    tmp = view[[c for c in tmp_cols if c in view.columns]].copy()
    tmp = tmp.rename(columns={"anomaly_type":"event"})
    ev = ev.merge(tmp, on=["ts","line","event"], how="left")

    # -----------------------------
    # Work Orders + PR/PO state
    # -----------------------------
    if "rd_tickets" not in st.session_state:
        st.session_state.rd_tickets = pd.DataFrame(columns=[
            "ticket_id","created_ts","line","subsystem","issue","severity","priority","suggested_action",
            "impact_nt_per_m","est_downtime_min","est_material_cost_nt","status","pr_id","po_id",
            "evidence_image","evidence_thermal","evidence_audio","evidence_uri"
        ])
    if "rd_pr" not in st.session_state:
        st.session_state.rd_pr = pd.DataFrame(columns=["pr_id","ticket_id","created_ts","status","item","qty","unit_cost_nt","amount_nt"])
    if "rd_po" not in st.session_state:
        st.session_state.rd_po = pd.DataFrame(columns=["po_id","pr_id","created_ts","vendor","status","amount_nt"])

    # -----------------------------
    # Auto-generate tickets
    # -----------------------------
    st.markdown("### 5) è‡ªå‹•ç”Ÿæˆç¶­ä¿®å·¥å–®ï¼ˆå« PR/POï¼‰")
    colA, colB, colC = st.columns([1.1, 1.1, 2.0])
    with colA:
        min_conf = st.slider("æœ€å°ä¿¡å¿ƒé–€æª»", 0.0, 0.99, 0.60, 0.01, key="rd_min_conf")
    with colB:
        include_green = st.checkbox("åŒ…å«ğŸŸ¢ï¼ˆå»ºè­°ä¸å‹¾ï¼‰", value=False, key="rd_inc_green")
    with colC:
        st.caption("è¦å‰‡ï¼šğŸŸ¡/ğŸ”´ ä¸” confidenceâ‰¥é–€æª» â†’ ç”Ÿæˆ Ticketï¼›æ¯å€‹ Ticket æœƒè‡ªå‹•ç”Ÿæˆ PRï¼ˆææ–™éœ€æ±‚ï¼‰ï¼ŒPR å¯å†è½‰ POã€‚")

    def _next_id(prefix: str, df: pd.DataFrame) -> str:
        if len(df) == 0:
            return f"{prefix}-0001"
        nums = []
        for x in df.iloc[:,0].astype(str).tolist():
            if x.startswith(prefix+"-"):
                try:
                    nums.append(int(x.split("-")[-1]))
                except Exception:
                    pass
        n = (max(nums) + 1) if nums else 1
        return f"{prefix}-{n:04d}"

    def generate_tickets_and_pr(ev_df: pd.DataFrame):
        # filter
        f = ev_df.copy()
        if not include_green:
            f = f[f["severity"].isin(["ğŸŸ¡","ğŸ”´"])]
        f = f[f["confidence"].astype(float) >= float(min_conf)] if "confidence" in f.columns else f

        if len(f) == 0:
            return 0

        tickets_new = []
        pr_new = []
        for _, r in f.iterrows():
            t = event_to_ticket_row(r)
            t["ticket_id"] = _next_id("MT", st.session_state.rd_tickets)
            tickets_new.append(t)

            # PR items
            items = ACTION_MAP.get(str(r["event"]), ACTION_MAP["UNKNOWN"])[1]
            pr_id = _next_id("PR", st.session_state.rd_pr)
            for item, qty, unit in items:
                amount = float(qty) * float(unit)
                pr_new.append({
                    "pr_id": pr_id,
                    "ticket_id": t["ticket_id"],
                    "created_ts": dt.datetime.now(),
                    "status": "DRAFT",
                    "item": item,
                    "qty": int(qty),
                    "unit_cost_nt": float(unit),
                    "amount_nt": float(amount),
                })
            # link ticket -> PR
            tickets_new[-1]["pr_id"] = pr_id

        st.session_state.rd_tickets = pd.concat([st.session_state.rd_tickets, pd.DataFrame(tickets_new)], ignore_index=True)
        st.session_state.rd_pr = pd.concat([st.session_state.rd_pr, pd.DataFrame(pr_new)], ignore_index=True)
        return len(tickets_new)

    gen_btn = st.button("ğŸ¤– ä¸€éµç”Ÿæˆç¶­ä¿®å·¥å–® + PRï¼ˆä¾è¦å‰‡ï¼‰", type="primary", use_container_width=True, key="rd_gen")
    if gen_btn:
        nnew = generate_tickets_and_pr(ev)
        st.success(f"âœ… å·²æ–°å¢ {nnew} ç­†ç¶­ä¿®å·¥å–®ï¼ˆä¸¦å»ºç«‹å°æ‡‰ PRï¼‰")

    # -----------------------------
    # Tickets table + selection
    # -----------------------------
    st.markdown("### 6) ç¶­ä¿®å·¥å–®ï¼ˆMaintenance Ticketsï¼‰")
    tdf = st.session_state.rd_tickets.copy()
    if len(tdf) == 0:
        st.info("å°šç„¡ç¶­ä¿®å·¥å–®ã€‚è«‹å…ˆæŒ‰ã€ä¸€éµç”Ÿæˆã€ã€‚")
    else:
        st.dataframe(
            tdf.sort_values(["priority","created_ts"], ascending=[True, False]),
            use_container_width=True,
            hide_index=True
        )

        sel = st.selectbox("é¸æ“‡ä¸€ç­†å·¥å–®æŸ¥çœ‹ evidence / PR / PO", tdf["ticket_id"].astype(str).tolist(), key="rd_ticket_sel")
        trow = tdf[tdf["ticket_id"].astype(str) == str(sel)].iloc[0].to_dict()

        st.markdown("#### Evidenceï¼ˆé»é–‹æŸ¥çœ‹ï¼‰")
        evc1, evc2, evc3 = st.columns(3)

        def _render_evidence(col, fname: str, kind: str):
            if not fname:
                col.info("ï¼ˆç„¡ï¼‰")
                return
            store = st.session_state.rd_evidence_store
            if fname not in store:
                col.warning(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{fname}ï¼ˆè«‹ä¸Šå‚³ evidenceï¼‰")
                return
            b = store[fname]
            if kind in ("image","thermal"):
                col.image(b, caption=fname, use_container_width=True)
            else:
                col.audio(b)

        with evc1:
            st.write("ğŸ“· å¯è¦‹å…‰")
            _render_evidence(evc1, str(trow.get("evidence_image","")), "image")
        with evc2:
            st.write("ğŸŒ¡ï¸ ç†±åƒ")
            _render_evidence(evc2, str(trow.get("evidence_thermal","")), "thermal")
        with evc3:
            st.write("ğŸ”Š éŸ³æª”")
            _render_evidence(evc3, str(trow.get("evidence_audio","")), "audio")

        st.markdown("#### PRï¼ˆè«‹è³¼ï¼‰")
        pr_id = str(trow.get("pr_id",""))
        pr_df = st.session_state.rd_pr
        pr_view = pr_df[pr_df["pr_id"].astype(str) == pr_id].copy() if pr_id else pd.DataFrame()
        if len(pr_view) == 0:
            st.info("æ­¤å·¥å–®å°šç„¡ PRã€‚")
        else:
            st.dataframe(pr_view, use_container_width=True, hide_index=True)
            total_amt = float(pr_view["amount_nt"].sum())
            st.metric("PR é‡‘é¡åˆè¨ˆ", f"NT$ {total_amt:,.0f}")

            # Approve PR -> create PO
            cA, cB = st.columns([1.2, 2.0])
            with cA:
                vendor = st.text_input("PO å» å•†ï¼ˆç¤ºä¾‹ï¼‰", "Default Vendor", key="rd_vendor")
            with cB:
                st.caption("æµç¨‹ï¼šPR(DRAFT) â†’ Approve â†’ PO(OPEN)ã€‚PoC ç‰ˆå…ˆç”¨æŒ‰éˆ•æ¨¡æ“¬ã€‚")

            approve = st.button("âœ… Approve PR â†’ Create PO", use_container_width=True, key="rd_approve_pr")
            if approve:
                # update PR status
                st.session_state.rd_pr.loc[st.session_state.rd_pr["pr_id"].astype(str) == pr_id, "status"] = "APPROVED"

                # create PO
                po_id = _next_id("PO", st.session_state.rd_po)
                st.session_state.rd_po = pd.concat([st.session_state.rd_po, pd.DataFrame([{
                    "po_id": po_id,
                    "pr_id": pr_id,
                    "created_ts": dt.datetime.now(),
                    "vendor": vendor,
                    "status": "OPEN",
                    "amount_nt": total_amt,
                }])], ignore_index=True)

                # link ticket -> PO
                st.session_state.rd_tickets.loc[st.session_state.rd_tickets["ticket_id"].astype(str) == str(sel), "po_id"] = po_id

                st.success(f"âœ… å·²å»ºç«‹ POï¼š{po_id}")

        st.markdown("#### POï¼ˆæ¡è³¼å–®ï¼‰")
        po_id = str(st.session_state.rd_tickets.loc[st.session_state.rd_tickets["ticket_id"].astype(str) == str(sel), "po_id"].iloc[0] or "")
        if po_id:
            po_view = st.session_state.rd_po[st.session_state.rd_po["po_id"].astype(str) == po_id].copy()
            st.dataframe(po_view, use_container_width=True, hide_index=True)
        else:
            st.info("æ­¤å·¥å–®å°šæœªå»ºç«‹ POï¼ˆè«‹å…ˆ Approve PRï¼‰ã€‚")

        st.markdown("### 7) ERP åŒ¯å‡ºï¼ˆExcel / PDFï¼‰")
        st.caption("å°‡ç›®å‰ RobotDog ç¶­ä¿®å·¥å–®ã€PRã€PO åŒ¯å‡ºæˆ ERP å¯æ¥æ”¶çš„æª”æ¡ˆæ ¼å¼ï¼ˆPoCï¼šExcel å¤šå·¥ä½œè¡¨ + PDF å ±è¡¨ï¼‰ã€‚")

        exp_c1, exp_c2, exp_c3 = st.columns([1.1, 1.1, 2.0])
        with exp_c1:
            xls_bytes = build_erp_excel(st.session_state.rd_tickets, st.session_state.rd_pr, st.session_state.rd_po)
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰ ERP Excelï¼ˆTickets+PR+POï¼‰",
                data=xls_bytes,
                file_name=f"YuYuan_ERP_Export_{dt.datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
                key="rd_export_excel",
            )

        with exp_c2:
            if _REPORTLAB_OK:
                pdf_bytes = build_erp_pdf(st.session_state.rd_tickets, st.session_state.rd_pr, st.session_state.rd_po)
                st.download_button(
                    "ğŸ“„ ä¸‹è¼‰ ERP PDFï¼ˆTickets+PR+POï¼‰",
                    data=pdf_bytes,
                    file_name=f"YuYuan_ERP_Export_{dt.datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                    key="rd_export_pdf",
                )
            else:
                st.warning("æ­¤ç’°å¢ƒæœªå®‰è£ reportlabï¼Œç„¡æ³•è¼¸å‡º PDFï¼ˆExcel å¯ç”¨ï¼‰ã€‚")

        with exp_c3:
            st.markdown("**ERP æ¬„ä½å»ºè­°ï¼ˆå¾ŒçºŒä¸²æ¥ï¼‰**")
            st.write("- Ticketsï¼šticket_id / created_ts / line / subsystem / issue / severity / priority / status / pr_id / po_id")
            st.write("- PRï¼špr_id / ticket_id / item / qty / unit_cost_nt / amount_nt / status")
            st.write("- POï¼špo_id / pr_id / vendor / amount_nt / status")

